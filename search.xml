<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[k8s iptables 规则查看]]></title>
    <url>%2F2018%2F11%2F29%2Fk8s-iptables%2F</url>
    <content type="text"><![CDATA[在访问 k8s 服务时，有时会出现一直连不上的问题，我们可以通过分析 iptables 和抓包的方式观察报文是否正确到达。关于 iptable 的介绍可以参考：iptables Iptables 跟踪设置如下，具体参考[1]: 12345678# Load the (IPv4) netfilter log kernel modulemodprobe nf_log_ipv4# Enable logging for the IPv4 (AF Family 2)sysctl net.netfilter.nf_log.2=nf_log_ipv4# restart rsyslogdsystemctl restart rsyslog 这里我们以 k8s NodePort 类型的 service 为例，假如我们希望追踪 23741 端口的规则，设置如下： 12iptables -t raw -j TRACE -p tcp --dport 32741 -I PREROUTING 1iptables -t raw -j TRACE -p tcp --dport 32741 -I OUTPUT 1 查看 /var/log/messages 中的追踪记录为了查看规则，现在某个机器上 curl 一下主机的 32741 端口。 1234567891011121314raw:PREROUTING:policy:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:PREROUTING:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-SERVICES:rule:9 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-NODEPORTS:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-MARK-MASQ:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-MARK-MASQ:return:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-NODEPORTS:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-SVC-4N57TFCL4MD7ZTDA:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-SEP-PJQYOXMI5CEBVECW:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000filter:FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000filter:KUBE-FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000raw:PREROUTING:policy:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=52 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343890 ACK=3563071810 WINDOW=4106 RES=0x00 ACK URGP=0 OPT (0101080A08CB9A71008611F0) 根据上面的图我们知道报文是按照 nat:PREROUTING -&gt; filter:FORWARD -&gt; nat:POSTROUTING 传输的。 按规则分析，先看第一条： 1nat:PREROUTING:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) iptables 的 PREROUTING 如下： 1234Chain PREROUTING (policy ACCEPT)target prot opt source destinationKUBE-SERVICES all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service portals */DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCAL 可以看出所有报文都会匹配第一条规则，也就是 KUBE-SERVICES, 也就是 trace 里的： 1nat:KUBE-SERVICES:rule:9 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) 再看 iptables 的 KUBE-SERVICES 1234567891011Chain KUBE-SERVICES (2 references)target prot opt source destinationKUBE-MARK-MASQ udp -- !192.168.3.0/24 192.168.2.10 /* kube-system/kube-dns:dns cluster IP */ udp dpt:53KUBE-SVC-TCOU7JCQXEZGVUNU udp -- 0.0.0.0/0 192.168.2.10 /* kube-system/kube-dns:dns cluster IP */ udp dpt:53KUBE-MARK-MASQ tcp -- !192.168.3.0/24 192.168.2.10 /* kube-system/kube-dns:dns-tcp cluster IP */ tcp dpt:53KUBE-SVC-ERIFXISQEP7F7OF4 tcp -- 0.0.0.0/0 192.168.2.10 /* kube-system/kube-dns:dns-tcp cluster IP */ tcp dpt:53KUBE-MARK-MASQ tcp -- !192.168.3.0/24 192.168.2.1 /* default/kubernetes:https cluster IP */ tcp dpt:443KUBE-SVC-NPX46M4PTMTKRN6Y tcp -- 0.0.0.0/0 192.168.2.1 /* default/kubernetes:https cluster IP */ tcp dpt:443KUBE-MARK-MASQ tcp -- !192.168.3.0/24 192.168.2.125 /* default/nginx: cluster IP */ tcp dpt:80KUBE-SVC-4N57TFCL4MD7ZTDA tcp -- 0.0.0.0/0 192.168.2.125 /* default/nginx: cluster IP */ tcp dpt:80KUBE-NODEPORTS all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL 很明显匹配的是 KUBE-NODEPORTS, 也就是： 1TRACE: nat:KUBE-NODEPORTS:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) iptables 的 KUBE-NODEPORTS 如下： 1234Chain KUBE-NODEPORTS (1 references)target prot opt source destinationKUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* default/nginx: */ tcp dpt:32741KUBE-SVC-4N57TFCL4MD7ZTDA tcp -- 0.0.0.0/0 0.0.0.0/0 /* default/nginx: */ tcp dpt:32741 先走第一个条 KUBE-MARK-MASQ 1TRACE: nat:KUBE-MARK-MASQ:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) iptables 的 KUBE-MARK-MASQ 如下： 123Chain KUBE-MARK-MASQ (11 references)target prot opt source destinationMARK all -- 0.0.0.0/0 0.0.0.0/0 MARK or 0x4000 k8s 会给报文打上 0x4000 的标签, 打完标签后会返回，然后继续匹配 KUBE-NODEPORTS 的下一条规则。也就是 KUBE-SVC-4N57TFCL4MD7ZTDA 12345TRACE: nat:KUBE-MARK-MASQ:return:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000TRACE: nat:KUBE-NODEPORTS:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000TRACE: nat:KUBE-SVC-4N57TFCL4MD7ZTDA:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-SVC-4N57TFCL4MD7ZTDA 如下： 123Chain KUBE-SVC-4N57TFCL4MD7ZTDA (2 references)target prot opt source destinationKUBE-SEP-PJQYOXMI5CEBVECW all -- 0.0.0.0/0 0.0.0.0/0 进入 KUBE-SEP-PJQYOXMI5CEBVECW 1TRACE: nat:KUBE-SEP-PJQYOXMI5CEBVECW:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-SEP-PJQYOXMI5CEBVECW 如下： 1234Chain KUBE-SEP-PJQYOXMI5CEBVECW (1 references)target prot opt source destinationKUBE-MARK-MASQ all -- 192.168.3.4 0.0.0.0/0DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp to:192.168.3.4:80 可以看到这里走的是 DNAT, 将报文中的目的地址换成了 92.168.3.4:80, 也就是 k8s 服务对应 pod 的 ip 和端口号。 DNAT 完了之后会将报文发给 filter 表的 FORWARD 链。 1TRACE: filter:FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 FORWARD 如下： 12345678910Chain FORWARD (policy DROP)target prot opt source destinationKUBE-FORWARD all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes forwarding rules */DOCKER-ISOLATION all -- 0.0.0.0/0 0.0.0.0/0DOCKER all -- 0.0.0.0/0 0.0.0.0/0ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHEDACCEPT all -- 0.0.0.0/0 0.0.0.0/0ACCEPT all -- 0.0.0.0/0 0.0.0.0/0ACCEPT all -- 192.168.3.0/24 0.0.0.0/0ACCEPT all -- 0.0.0.0/0 192.168.3.0/24 可以看到匹配第一条，进入 KUBE-FORWARD 1TRACE: filter:KUBE-FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-FORWARD 如下： 12345Chain KUBE-FORWARD (1 references)target prot opt source destinationACCEPT all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes forwarding rules */ mark match 0x4000/0x4000ACCEPT all -- 192.168.3.0/24 0.0.0.0/0 /* kubernetes forwarding conntrack pod source rule */ ctstate RELATED,ESTABLISHEDACCEPT all -- 0.0.0.0/0 192.168.3.0/24 /* kubernetes forwarding conntrack pod destination rule */ ctstate RELATED,ESTABLISHED forward 完了之后会转给 iptables 的 nat 表的 POSTROUTING: 1TRACE: nat:POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 POSTROUTING 如下： 12345678Chain POSTROUTING (policy ACCEPT)target prot opt source destinationKUBE-POSTROUTING all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes postrouting rules */MASQUERADE all -- 172.17.0.0/16 0.0.0.0/0RETURN all -- 192.168.3.0/24 192.168.3.0/24MASQUERADE all -- 192.168.3.0/24 !224.0.0.0/4RETURN all -- !192.168.3.0/24 192.168.3.0/24MASQUERADE all -- !192.168.3.0/24 192.168.3.0/24 命中第一条，转给 KUBE-POSTROUTING 1TRACE: nat:KUBE-POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-POSTROUTING 如下： 123Chain KUBE-POSTROUTING (1 references)target prot opt source destinationMASQUERADE all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service traffic requiring SNAT */ mark match 0x4000/0x4000 汇总一下，大概路线如下： 1234567891011121314151617181920212223242526--&gt; [nat]PREROUTING | | V [nat]KUBE-SERVICES | | V [nat]KUBE-NODEPORTS | | V [nat]KUBE-MARK-MASQ (打0x4000的标签) | | V [nat]KUBE-NODEPORTS | | V [nat]KUBE-SVC-4N57TFCL4MD7ZTDA [filter]KUBE-FORWARD -----&gt; [nat]POSTROUTING | ^ | | | | V | V [nat]KUBE-SEP-PJQYOXMI5CEBVECW ------------&gt;[filter]FORWARD [nat]KUBE-POSTROUTING(DNAT, 替换DST和DPT, 将物理机地址换成pod地址) 清除追踪规则 查看规则 number 12345678$ sudo iptables -t raw -nL --line-numberChain PREROUTING (policy ACCEPT)num target prot opt source destination1 TRACE tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:32741Chain OUTPUT (policy ACCEPT)num target prot opt source destination1 TRACE tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:32741 删除规则上面查到的 number 是 1, 这里删除第一条规则： 12$ sudo iptables -t raw -D PREROUTING 1$ sudo iptables -t raw -D OUTPUT 1 参考文献[1] How to trace IPTables]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之job]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-job%2F</url>
    <content type="text"><![CDATA[Kubernetes 有两种类型的 job, 分别是 Job 和 CronJonb。 Job: 负责批量处理短暂的一次性任务，仅执行一次，并保证处理的一个或者多个Pod成功结束。 CronJob: 负责定时任务，在指定的时间周期运行指定的任务。]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之configmap]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-configmap%2F</url>
    <content type="text"><![CDATA[很多生产环境中的应用程序较为复杂，可能需要多个 config 文件，命令行参数和环境变量的组合。并且这些配置信息应该从镜像中解耦出来，以保证镜像的可移植性以及配置信息不被泄漏。社区使用 ConfigMap 满足这一需求。 ConfigMap 包含了一系列键值对，用于存储被 pod 或者系统组件（如 controller 等）访问的信息。 configmap 模板12345678910111213apiVersion: v1kind: ConfigMapmetadata: creationTimestamp: 2018-11-21T09:56:37 name: example-conifg namespace: defaultdata: example.property.1: hello example.property.2: world example.property.file: |- property.1=value-1 property.2=value-2 property.3=value-3]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之daemonset]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-daemonset%2F</url>
    <content type="text"></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之deployment]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-deployment%2F</url>
    <content type="text"><![CDATA[Deployment 多用于为 pod 和 replia set 提供更新，并且可以方便地跟踪观察其所属的 replica set 或者 pod 数量以及状态的变化。 Node 调度有时候我们希望 pod 运行在指定的一个或者一批 node 上。可以通过 node 的名字或者 label 来完成。 NodeNamePod.spec.nodeName用于强制约束将Pod调度到指定的Node节点上，这里说是“调度”，但其实指定了nodeName的Pod会直接跳过Scheduler的调度逻辑，直接写入PodList列表，该匹配规则是强制匹配。 eg: 1234567891011121314151617apiVersion: apps/v1kind: Deploymentmetadata: name: my-deployspec: replicas: 1 template: metadata: labels: app: my-app spec: nodeName: master # 指定调度到master节点 containers: - name: nginx image: nginx ports: - containerPort: 80 NodeSelector Pod.spec.nodeSelector是通过kubernetes的label-selector机制进行节点选择，由scheduler调度策略 MatchNodeSelector进行label匹配，调度pod到目标节点，该匹配规则是强制约束。 查看节点 label1kubectl get nodes --show-labels 添加 label1234kubectl label nodes &lt;node_name&gt; &lt;key&gt;=&lt;value&gt;# eg:kubectl label nodes master region=shanghai pod 中指定 label123456789101112131415161718apiVersion: apps/v1kind: Deploymentmetadata: name: my-deployspec: replicas: 1 template: metadata: labels: app: my-app spec: nodeSelector: region: shanghai # 指定调度到上海的节点 containers: - name: nginx image: nginx ports: - containerPort: 80]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之rs]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-rs%2F</url>
    <content type="text"></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之rc]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-rc%2F</url>
    <content type="text"></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之service]]></title>
    <url>%2F2018%2F11%2F20%2Fk8s-service%2F</url>
    <content type="text"><![CDATA[由于重新调度等原因，pod 在 kubernetes 中的 IP 地址不是固定的，因此需要一个代理来确保使用 pod 的应用不需要知晓 pod 的真实 IP 地址。另一个原因是当使用 replication controller 创建了多个 pod 副本时，需要一个代理来为这些 pod 做负载均衡。 service 主要由一个 IP 地址和 label selector 构成。在创建之初，每个 service 便被分配了一个独一无二的 IP 地址，该 IP 地址与 service 的生命周期相同，且不再更改。 service 工作原理userspace 模式iptables 模式service 的自发现环境变量方式环境变量的注入只发生在 pod 创建时，且不会被自动更新。 DNS 方式DNS 缓存问题会导致如下两种不可靠情况 DNS 函数库对 DNS TTL 支持不良问题由来已久。 即使应用程序和 DNS 服务器能够进行恰当的域名重解析操作，每个客户端频繁的域名重解析请求将给系统带来极大的负荷。 service 外部路由service 通常分为三种类型，分别为 ClusterIP, NodePort 和 Loadbalancer。其中 ClusterIP 是最基本的类型，在默认情况下只能在集群内部访问。 NodePortLoadbalancerLoadbalancer 类型的 service 并不是由 kubernetes 集群维护的，需要云服务提供商的支持。如何将外部 loadbalancer 接入的流量导到后端 pod，取决于具体云服务提供商的实现。 external ipservice 模板1234567891011apiVersion: v1kind: Servicemetadata: name: appspec: selector: app: app type: NodePort ports: - protocol: TCP port: 5000]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之pod]]></title>
    <url>%2F2018%2F11%2F20%2Fk8s-pod%2F</url>
    <content type="text"><![CDATA[在 Kubernetes 中，能够被创建，调度和管理的最小单元是 pod, 而非单个容器。一个 pod 是由若干个 Docker 容器构成的容器组（pod意为豆荚）。 pod里的容器共享 network namespace, 并通过 volume 机制共享一部分存储。 pod里的容器共享如下资源： pod 是IP等网络资源分配的基本单位，这个IP及network namespace是由pod里的容器共享的。 pod内的所有容器也共享volume。 IPC namespace UTS namespace label每个pod都有一个属性labels – 一组键值对，例如： 1234&quot;labels&quot;: &#123; &quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;&#125; 相等查询12environment = productiontier != frontend 子集查询123environment in (production, qa)tier notin (frontend, backend)partition pod 模板12345678910111213kind: Podmetadata: name: busybox namespace: defaultspec: containers: - name: busybox image: busybox command: - sleep - &quot;36000&quot; imagePullPolicy: IfNotPresent restartPolicy: Always 常用命令根据 label 获取 pod1kubectl get pods -l name=nginx]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeadm 安装 k8s]]></title>
    <url>%2F2018%2F11%2F20%2Fk8s-install%2F</url>
    <content type="text"><![CDATA[本文介绍使用 kubeadm 安装 k8s 集群。建议不要用在生产环境。使用 kubeadm 安装，如果 master 节点挂了，是没有办法操作的。 安装版本： k8s: 1.12.2 docker: 17.3.2 防火墙配置1234567# 关闭 firewalldsystemctl disable firewalldsystemctl stop firewalld# 关闭 selinuxsetenforce 0sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config 内核参数配置1echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables hosts 配置在 /etc/hosts 文件中配置集群的主机，例如： 123192.168.1.2 master192.168.1.3 node1192.168.1.4 node2 yum 源配置添加 docker 源CentOS 默认源的docker版本比较低，很多特性不支持，另外k8s对docker版本有要求，这里我们配置 docker-ce 源。 12yum-config-manager --add-repo \ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 添加 k8s 源12345678910cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 安装 docker由于 k8s 对 docker 版本有要求，最新的 docker 版本不一定支持，这里安装指定版本。 123456789# 查看可用版本yum list docker-ce --showduplicatesyum install -y --setopt=obsoletes=0 \ docker-ce-17.03.2.ce-1.el7.centos.x86_64 \ docker-ce-selinux-17.03.2.ce-1.el7.centos.noarchsystemctl enable dockersystemctl start docker 安装 kubeadm 和 kubectl123yum install -y kubeadm kubectlsystemctl enable kubelet 下载 k8s 镜像由于网络原因，kubeadm 需要的镜像无法下载，这里我们使用别人的代理下载。 查看所需 docker 镜像12# 这个命令仅使用 v1.10 以上kubeadm config images list 添加 pullimages.sh 脚本, 并执行， 脚本内容如下： 123456789101112131415#!/bin/bashimages=( kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2)for imageName in $&#123;images[@]&#125; ; do docker pull anjia0532/google-containers.$imageName docker tag anjia0532/google-containers.$imageName k8s.gcr.io/$imageName docker rmi anjia0532/google-containers.$imageNamedone 初始化集群1234kubeadm init \ --kubernetes-version=v1.12.2 \ --pod-network-cidr=192.168.3.0/24 \ --service-cidr=192.168.2.0/24 master 参与调度默认情况下集群不会调度 pod 到 master 节点，可以执行如下命令来控制 1kubectl taint nodes --all node-role.kubernetes.io/master- 命令补全1234yum install -y bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc servcie 端口范围修改k8s service 默认的端口范围是 30000-32767, 如果想修改端口范围，进行如下操作： 修改 /etc/kubernetes/manifests/kube-apiserver.yaml，添加： --service-node-port-range=80-32767 systemctl restart kubelet.service 常见问题Dns loop detected 编辑 configmap 1kubectl -n kube-system edit configmap coredns 注释掉 loop 12345678910111213141516171819202122apiVersion: v1data: Corefile: | .:53 &#123; errors health kubernetes cluster.local in-addr.arpa ip6.arpa &#123; pods insecure upstream fallthrough in-addr.arpa ip6.arpa &#125; prometheus :9153 proxy . /etc/resolv.conf cache 30 #loop reload loadbalance &#125;kind: ConfigMapmetadata: creationTimestamp: 2018-11-20T03:08:28Z name: coredns token 过期token 默认有效期是 24h, 如果 token 过期了，创建新 token 再加入集群： 1kubeadm token create 其它节点 pod cidr 问题 查看节点是否设置了 pod cidekubectl get nodes -o jsonpath=&#39;{.items[*].spec.podCIDR}&#39; 如果没有设置，设置节点的 pod CIDRkubectl patch node &lt;NODE_NAME&gt; -p &#39;{&quot;spec&quot;:{&quot;podCIDR&quot;:&quot;&lt;SUBNET&gt;&quot;}}&#39; 参考： flannel Troubleshooting]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 三剑客]]></title>
    <url>%2F2018%2F11%2F18%2Fdocker-scm%2F</url>
    <content type="text"><![CDATA[docker 三剑客主要用于容器的编排。 创建服务docker service create –replicas 2 –name hello app 服务规模调整docker service scale hello=3docker stack deploy -c docker-compose.yml hello 关闭服务docker stack rm hello 滚动更新task 概念 离开集群docker swarm leave –force 容器运行节点docker stack ps volume + bind mounts 设置节点状态1234# 禁用docker node update --availability drain work1# 启用docker node update --availability active worker1 查看 Tokendocker swarm join-token worker/manager docker config 配置docker network create –attachable –driver overlay oneta 123456version: &quot;3&quot;networks: mynet: driver: overlay attachable: trueservices:]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq]]></title>
    <url>%2F2018%2F10%2F17%2Frabbitmq%2F</url>
    <content type="text"><![CDATA[Exchange在生产者/消费者模型中，生产者是不会直接将消息发送到队列的，生产者只能把消息发送到 exchange 上。 先看一个简单的模型： exchange 的一端是生产者，另一端是队列，exchange 需要知道把消息发送到哪些队列。 有了 exchange 和队列之后，需要进行 bindings, 来告诉 exchange 把消息发送到指定队列。 123channel.queue_bind(exchange=exchange_name, queue=queue_name, routing_key='black') 在 bindings 的时候，可以指定 routing_key，来控制消息要发送的队列。 当然多个队列可以有相同的 routing_key 一个完整的生产者消费者模型如下： 根据不同的规则，rabbitmq 划分了四种 exchange： Direct Fanout: 把消息发送到所有绑定的队列； Topic: Headers]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go io]]></title>
    <url>%2F2018%2F08%2F22%2Fgo-io%2F</url>
    <content type="text"><![CDATA[go 语言的标准库 io 包主要定义了常用的 io接口，具体如如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 读取接口type Reader interface &#123; Read(p []byte) (n int, err error)&#125;// 写接口type Writer interface &#123; Write(p []byte) (n int, err error)&#125;// 关闭读写type Closer interface &#123; Close() error&#125;// 指定位置type Seeker interface &#123; Seek(offset int64, whence int) (int64, error)&#125;// 指定位置读取type ReaderAt interface &#123; ReadAt(p []byte, off int64) (n int, err error)&#125;// io 包还提供了一些组合接口type ReadSeeker interface &#123; Reader Seeker&#125;type WriteCloser interface &#123; Writer Closer&#125;type WriteSeeker interface &#123; Writer Seeker&#125;type ReadWriter interface &#123; Reader Writer&#125;type ReadWriteCloser interface &#123; Reader Writer Closer&#125;type ReadWriteSeeker interface &#123; Reader Writer Seeker&#125; 实现了上面接口的包如下： strings.Reader 实现了 io.Reader os.File 同时实现了 io.Reader 和 io.Writer net.conn 实现了 io.Reader, io.Writer, io.Close bufio.Reader/Writer 分别实现了io.Reader 和 io.Writer bytes.Buffer 同时实现了 io.Reader 和 io.Writer bytes.Reader 实现了io.Reader ioutil 12// 读取所有数据func ReadAll(r io.Reader) ([]byte, error)]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables 介绍]]></title>
    <url>%2F2018%2F06%2F29%2Fiptables%2F</url>
    <content type="text"><![CDATA[在Linux系统中，对于防火墙的实现一般分为包过滤防火墙，TCP-Wrapper即程序管控，代理服务器等几种方式。其中，iptables作为一种基于包过滤方式的防火墙工具，在实际中应用非常广泛，是非常重要的一个安全工具。真正实现防火墙功能的是 netfilter，它是一个 linux 内核模块，做实际的包过滤。实际上，除了 iptables 以外，还有很多类似的用户空间工具。 iptable 介绍 iptables的“链”与“表”netfilter 使用表（table）和 链（chain）来组织网络包的处理规则（rule）。它默认定义了以下表和链： filter表主要用于对数据包进行过滤，根据具体的规则决定是否放行该数据包（如DROP、ACCEPT、REJECT、LOG）。filter 表对应的内核模块为iptable_filter，包含三个规则链： INPUT链：INPUT针对那些目的地是本地的包 FORWARD链：FORWARD过滤所有不是本地产生的并且目的地不是本地(即本机只是负责转发)的包 OUTPUT链：OUTPUT是用来过滤所有本地生成的包 nat表主要用于修改数据包的IP地址、端口号等信息（网络地址转换，如SNAT、DNAT、MASQUERADE、REDIRECT）。属于一个流的包(因为包的大小限制导致数据可能会被分成多个数据包)只会经过这个表一次。如果第一个包被允许做NAT或Masqueraded，那么余下的包都会自动地被做相同的操作，也就是说，余下的包不会再通过这个表。表对应的内核模块为 iptable_nat，包含三个链： PREROUTING链：作用是在包刚刚到达防火墙时改变它的目的地址 OUTPUT链：改变本地产生的包的目的地址 POSTROUTING链：在包就要离开防火墙之前改变其源地址 mangle表主要用于修改数据包的TOS（Type Of Service，服务类型）、TTL（Time To Live，生存周期）指以及为数据包设置Mark标记，以实现Qos(Quality Of Service，服务质量)调整以及策略路由等应用，由于需要相应的路由设备支持，因此应用并不广泛。包含五个规则链——PREROUTING，POSTROUTING，INPUT，OUTPUT，FORWARD。 raw表是自1.2.9以后版本的iptables新增的表，主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表的规则要优先于其他表。包含两条规则链——OUTPUT、PREROUTING iptables中数据包和4种被跟踪连接的4种不同状态： NEW：该包想要开始一个连接（重新连接或将连接重定向） RELATED：该包是属于某个已经建立的连接所建立的新连接。例如：FTP的数据传输连接就是控制连接所 - - - RELATED出来的连接。–icmp-type 0 ( ping 应答) 就是–icmp-type 8 (ping 请求)所RELATED出来的。 ESTABLISHED：只要发送并接到应答，一个数据连接从NEW变为ESTABLISHED,而且该状态会继续匹配这个连接的后续数据包。 INVALID：数据包不能被识别属于哪个连接或没有任何状态比如内存溢出，收到不知属于哪个连接的ICMP错误信息，一般应该DROP这个状态的任何数据。 防火墙处理数据包的方式（规则）： ACCEPT：允许数据包通过 DROP：直接丢弃数据包，不给任何回应信息 REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息。 SNAT：源地址转换。在进入路由层面的route之后，出本地的网络栈之前，改写源地址，目标地址不变，并在本机建立NAT表项，当数据返回时，根据NAT表将目的地址数据改写为数据发送出去时候的源地址，并发送给主机。解决内网用户用同一个公网地址上网的问题。MASQUERADE，是SNAT的一种特殊形式，适用于像adsl这种临时会变的ip上 DNAT:目标地址转换。和SNAT相反，IP包经过route之前，重新修改目标地址，源地址不变，在本机建立NAT表项，当数据返回时，根据NAT表将源地址修改为数据发送过来时的目标地址，并发给远程主机。可以隐藏后端服务器的真实地址。（感谢网友提出之前这个地方与SNAT写反了） REDIRECT：是DNAT的一种特殊形式，将网络包转发到本地host上（不管IP头部指定的目标地址是啥），方便在本机做端口转发。 LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则。 除去最后一个LOG，前3条规则匹配数据包后，该数据包不会再往下继续匹配了，所以编写的规则顺序极其关键。 iptables编写规则命令格式： [-t 表名]：该规则所操作的哪个表，可以使用filter、nat等，如果没有指定则默认为filter -A：新增一条规则，到该规则链列表的最后一行 -I：插入一条规则，原本该位置上的规则会往后顺序移动，没有指定编号则为1 -D：从规则链中删除一条规则，要么输入完整的规则，或者指定规则编号加以删除 -R：替换某条规则，规则替换不会改变顺序，而且必须指定编号。 -P：设置某条规则链的默认动作 -nL：-L、-n，查看当前运行的防火墙规则列表 chain名：指定规则表的哪个链，如INPUT、OUPUT、FORWARD、PREROUTING等 [规则编号]：插入、删除、替换规则时用，–line-numbers显示号码 [-i|o 网卡名称]：i是指定数据包从哪块网卡进入，o是指定数据包从哪块网卡输出 [-p 协议类型]：可以指定规则应用的协议，包含tcp、udp和icmp等 [-s 源IP地址]：源主机的IP地址或子网地址 [--sport 源端口号]：数据包的IP的源端口号 [-d目标IP地址]：目标主机的IP地址或子网地址 [--dport目标端口号]：数据包的IP的目标端口号 -m：extend matches，这个选项用于提供更多的匹配参数，如： -m state –state ESTABLISHED,RELATED -m tcp –dport 22 -m multiport –dports 80,8080 -m icmp –icmp-type 8 &lt;-j 动作&gt;：处理数据包的动作，包括ACCEPT、DROP、REJECT等 具体实例请参考 iptables常用实例备查。]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[画图工具介绍]]></title>
    <url>%2F2018%2F06%2F19%2Fdiagram%2F</url>
    <content type="text"><![CDATA[在我们写文档的时候常常需要插入一些图片来辅助说明，文档可以用 git 来管理，换个人很容易修改，但是图片如果没有原图很难修改。这里我们介绍几款代码画图工具，可以很方便的用 git 管理。 plantuml看名字就知道这个工具是用来画 uml 图的。 plantuml 在国外使用比较广泛，很多 web 工具都支持 plantuml. plantuml 支持以下几种类型的 uml 图： Sequence diagram Usecase diagram Class diagram Activity diagram Component diagram State diagram Object diagram Deployment diagram Timing diagram plantuml 也支持几种非 uml 的图，具体如下： Wireframe graphical interface Archimate diagram Specification and Description Language (SDL) Ditaa diagram Gantt diagram Mathematic with AsciiMath or JLaTeXMath notation 使用方法Sequence diagram基本用法 1234567@startumlAlice -&gt; Bob: Authentication RequestBob --&gt; Alice: Authentication ResponseAlice -&gt; Bob: Another authentication RequestAlice &lt;-- Bob: another authentication Response@enduml 声明参与者 1234567891011121314@startumlactor Foo1boundary Foo2control Foo3entity Foo4database Foo5collections Foo6Foo1 -&gt; Foo2 : To boundaryFoo1 -&gt; Foo3 : To controlFoo1 -&gt; Foo4 : To entityFoo1 -&gt; Foo5 : To databaseFoo1 -&gt; Foo6 : To collections@enduml 添加注释 1234567891011121314@startumlAlice-&gt;Bob : hellonote left: this is a first noteBob-&gt;Alice : oknote right: this is another noteBob-&gt;Bob : I am thinkingnote left a note can also be defined on several linesend note@enduml Usecase diagram1234567891011121314151617181920@startuml:Main Admin: as Admin(Use the application) as (Use)User -&gt; (Start)User --&gt; (Use)Admin ---&gt; (Use)note right of Admin : This is an example.note right of (Use) A note can also be on several linesend notenote &quot;This note is connected\nto several objects.&quot; as N2(Start) .. N2N2 .. (Use)@enduml Class diagram1234567@startumlClass01 &lt;|-- Class02Class03 *-- Class04Class05 o-- Class06Class07 .. Class08Class09 -- Class10@enduml 1234567@startumlClass11 &lt;|.. Class12Class13 --&gt; Class14Class15 ..&gt; Class16Class17 ..|&gt; Class18Class19 &lt;--* Class20@enduml 1234567@startumlClass21 #-- Class22Class23 x-- Class24Class25 &#125;-- Class26Class27 +-- Class28Class29 ^-- Class30@enduml 指定关系 123456789@startumlClass01 &quot;1&quot; *-- &quot;many&quot; Class02 : containsClass03 o-- Class04 : aggregationClass05 --&gt; &quot;1&quot; Class06@enduml 属性类型 12345678@startumlclass Dummy &#123; -field1 #field2 ~method1() +method2()&#125; Activity diagram12345678910111213141516@startumlstartif (multiprocessor?) then (yes) fork :Treatment 1; fork again :Treatment 2; end forkelse (monoproc) :Treatment 1; :Treatment 2;endif@enduml State diagram1234567891011121314151617181920@startumlscale 600 width[*] -&gt; State1State1 --&gt; State2 : SucceededState1 --&gt; [*] : AbortedState2 --&gt; State3 : SucceededState2 --&gt; [*] : Abortedstate State3 &#123; state &quot;Accumulate Enough Data\nLong State Name&quot; as long1 long1 : Just a test [*] --&gt; long1 long1 --&gt; long1 : New Data long1 --&gt; ProcessData : Enough Data&#125;State3 --&gt; State3 : FailedState3 --&gt; [*] : Succeeded / Save ResultState3 --&gt; [*] : Aborted @enduml Object diagram123456789101112131415@startumlobject Object01object Object02object Object03object Object04object Object05object Object06object Object07object Object08Object01 &lt;|-- Object02Object03 *-- Object04Object05 o-- &quot;4&quot; Object06Object07 .. Object08 : some labels@enduml Deployment diagram支持类型 1234567891011121314151617181920212223@startumlactor actoragent agentartifact artifactboundary boundarycard cardcloud cloudcomponent componentcontrol controldatabase databaseentity entityfile filefolder folderframe frameinterface interfacenode nodepackage packagequeue queuestack stackrectangle rectanglestorage storageusecase usecase@enduml 12345678910111213@startumlnode node1node node2node node3node node4node node5node1 -- node2node1 .. node3node1 ~~ node4node1 == node5@enduml Timing diagram12345678910111213141516171819202122232425@startumlrobust &quot;DNS Resolver&quot; as DNSrobust &quot;Web Browser&quot; as WBconcise &quot;Web User&quot; as WU@0WU is IdleWB is IdleDNS is Idle@+100WU -&gt; WB : URLWU is WaitingWB is Processing@+200WB is WaitingWB -&gt; DNS@+50 : Resolve URL@+100DNS is Processing@+300DNS is Idle@enduml Wireframe graphical interface1234567891011121314@startsalt&#123;+&#123;* File | Edit | Source | Refactor Refactor | New | Open File | - | Close | Close All &#125;&#123;/ General | Fullscreen | Behavior | Saving &#125;&#123; &#123; Open image in: | ^Smart Mode^ &#125; [X] Smooth images when zoomed [X] Confirm image deletion [ ] Show hidden images &#125;[Close]&#125;@endsalt Archimate diagram123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@startumlsprite $bProcess jar:archimate/business-processsprite $aService jar:archimate/application-servicesprite $aComponent jar:archimate/application-componentarchimate #Business &quot;Handle claim&quot; as HC &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Capture Information&quot; as CI &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Notify\nAdditional Stakeholders&quot; as NAS &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Validate&quot; as V &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Investigate&quot; as I &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Pay&quot; as P &lt;&lt;business-process&gt;&gt;HC *-down- CIHC *-down- NASHC *-down- VHC *-down- IHC *-down- PCI -right-&gt;&gt; NASNAS -right-&gt;&gt; VV -right-&gt;&gt; II -right-&gt;&gt; Parchimate #APPLICATION &quot;Scanning&quot; as scanning &lt;&lt;application-service&gt;&gt;archimate #APPLICATION &quot;Customer admnistration&quot; as customerAdministration &lt;&lt;application-service&gt;&gt;archimate #APPLICATION &quot;Claims admnistration&quot; as claimsAdministration &lt;&lt;application-service&gt;&gt;archimate #APPLICATION Printing &lt;&lt;application-service&gt;&gt;archimate #APPLICATION Payment &lt;&lt;application-service&gt;&gt;scanning -up-&gt; CIcustomerAdministration -up-&gt; CIclaimsAdministration -up-&gt; NASclaimsAdministration -up-&gt; VclaimsAdministration -up-&gt; IPayment -up-&gt; PPrinting -up-&gt; VPrinting -up-&gt; Parchimate #APPLICATION &quot;Document\nManagement\nSystem&quot; as DMS &lt;&lt;application-component&gt;&gt;archimate #APPLICATION &quot;General\nCRM\nSystem&quot; as CRM &lt;&lt;application-component&gt;&gt;archimate #APPLICATION &quot;Home &amp; Away\nPolicy\nAdministration&quot; as HAPA &lt;&lt;application-component&gt;&gt;archimate #APPLICATION &quot;Home &amp; Away\nFinancial\nAdministration&quot; as HFPA &lt;&lt;application-component&gt;&gt;DMS .up.|&gt; scanningDMS .up.|&gt; PrintingCRM .up.|&gt; customerAdministrationHAPA .up.|&gt; claimsAdministrationHFPA .up.|&gt; Paymentlegend leftExample from the &quot;Archisurance case study&quot; (OpenGroup).See ==&lt;$bProcess&gt; :business process==&lt;$aService&gt; : application service==&lt;$aComponent&gt; : appplication componentendlegend@enduml Specification and Description Language (SDL)也是活动图 12345678910111213141516@startumlstartif (multiprocessor?) then (yes) fork :Treatment 1; fork again :Treatment 2; end forkelse (monoproc) :Treatment 1; :Treatment 2;endif@enduml Ditaa diagram1234567891011@startditaa+--------+ +-------+ +-------+| +---+ ditaa +--&gt; | || Text | +-------+ |diagram||Document| |!magic!| | || &#123;d&#125;| | | | |+---+----+ +-------+ +-------+ : ^ | Lots of work | +-------------------------+@endditaa Gantt diagram123456789101112@startganttproject starts the 2018/04/09saturday are closedsunday are closed2018/05/01 is closed2018/04/17 to 2018/04/19 is closed[Prototype design] lasts 14 days[Test prototype] lasts 4 days[Test prototype] starts at [Prototype design]&apos;s end[Prototype design] is colored in Fuchsia/FireBrick [Test prototype] is colored in GreenYellow/Green @endgantt Mathematic with AsciiMath or JLaTeXMath notation123456789@startuml:&lt;math&gt;int_0^1f(x)dx&lt;/math&gt;;:&lt;math&gt;x^2+y_1+z_12^34&lt;/math&gt;;note rightTry also&lt;math&gt;d/dxf(x)=lim_(h-&gt;0)(f(x+h)-f(x))/h&lt;/math&gt;&lt;latex&gt;P(y|\mathbf&#123;x&#125;) \mbox&#123; or &#125; f(\mathbf&#123;x&#125;)+\epsilon&lt;/latex&gt;end note@enduml python 画图工具python 也提供了几个画图工具，如果使用 sphinx 编写文档，可以直接把代码嵌套到文档中。 blockdiag seqdiag actdiag nwdiag 安装1234pip install blockdiagpip install seqdiagpip install actdiagpip install nwdiag 简单使用生成图片一般用指定命令接文件名即可： 1blockdiag test.diag blockdiag123456blockdiag &#123; orientation = portrait A -&gt; B -&gt; C; B -&gt; D;&#125; blockdiag 可以设置很多属性，例如图片类型，颜色，大小，特效等。 1234567blockdiag &#123; // Set stacked to nodes. stacked [stacked]; ellipse [shape = &quot;ellipse&quot;, stacked]; stacked -&gt; ellipse;&#125; 123blockdiag &#123; A -&gt; B [label=&apos;text&apos;, fontsize=16];&#125; seqdiagseqdiag 用来画时序图： 12345678seqdiag &#123; browser -&gt; webserver [label = &quot;GET /index.html&quot;]; browser &lt;-- webserver; browser -&gt; webserver [label = &quot;POST /blog/comment&quot;]; webserver -&gt; database [label = &quot;INSERT comment&quot;]; webserver &lt;-- database; browser &lt;-- webserver;&#125; 12345678910111213seqdiag &#123; A -&gt; B; // Separator === Separator line === A -&gt; B; // Delay separator ... Separator line ... A -&gt; B;&#125; 123456789seqdiag &#123; // Use note (put note on rightside) browser -&gt; webserver [note = &quot;request\nGET /&quot;]; browser &lt;- webserver; // Use leftnote and rightnote browser -&gt; webserver [leftnote = &quot;send request&quot;]; browser &lt;- webserver [rightnote = &quot;send response&quot;];&#125; actdiagactdiag 用来画活动图： 123456789101112actdiag &#123; write -&gt; convert -&gt; image lane user &#123; label = &quot;User&quot; write [label = &quot;Writing reST&quot;]; image [label = &quot;Get diagram IMAGE&quot;]; &#125; lane actdiag &#123; convert [label = &quot;Convert reST to Image&quot;]; &#125;&#125; nwdiagnwdiag 主要用来画网络连线图，报文结构等。 普通网络图： 12345678910111213141516nwdiag &#123; network dmz &#123; address = &quot;210.x.x.x/24&quot; web01 [address = &quot;210.x.x.1&quot;]; web02 [address = &quot;210.x.x.2&quot;]; &#125; network internal &#123; address = &quot;172.x.x.x/24&quot;; web01 [address = &quot;172.x.x.1&quot;]; web02 [address = &quot;172.x.x.2&quot;]; db01; db02; &#125;&#125; 指定多个 ip: 1234567891011121314151617nwdiag &#123; network dmz &#123; address = &quot;210.x.x.x/24&quot; // set multiple addresses (using comma) web01 [address = &quot;210.x.x.1, 210.x.x.20&quot;]; web02 [address = &quot;210.x.x.2&quot;]; &#125; network internal &#123; address = &quot;172.x.x.x/24&quot;; web01 [address = &quot;172.x.x.1&quot;]; web02 [address = &quot;172.x.x.2&quot;]; db01; db02; &#125;&#125; 分组 123456789101112131415161718192021222324nwdiag &#123; network Sample_front &#123; address = &quot;192.168.10.0/24&quot;; // define group group web &#123; web01 [address = &quot;.1&quot;]; web02 [address = &quot;.2&quot;]; &#125; &#125; network Sample_back &#123; address = &quot;192.168.20.0/24&quot;; web01 [address = &quot;.1&quot;]; web02 [address = &quot;.2&quot;]; db01 [address = &quot;.101&quot;]; db02 [address = &quot;.102&quot;]; // define network using defined nodes group db &#123; db01; db02; &#125; &#125;&#125; peer networks 12345678910nwdiag &#123; inet [shape = cloud]; inet -- router; network &#123; router; web01; web02; &#125;&#125; 1234567891011121314rackdiag &#123; // define height of rack 16U; // define rack items 1: UPS [2U]; 3: DB Server 4: Web Server 1 // put 2 units to rack-level 4 4: Web Server 2 5: Web Server 3 5: Web Server 4 7: Load Balancer 8: L3 Switch&#125; 多个 1234567891011121314151617181920212223242526272829rackdiag &#123; // define 1st rack rack &#123; 16U; // define rack items 1: UPS [2U]; 3: DB Server 4: Web Server 5: Web Server 6: Web Server 7: Load Balancer 8: L3 Switch &#125; // define 2nd rack rack &#123; 12U; // define rack items 1: UPS [2U]; 3: DB Server 4: Web Server 5: Web Server 6: Web Server 7: Load Balancer 8: L3 Switch &#125;&#125; TCP 报文结构 12345678910111213141516171819202122&#123; colwidth = 32 node_height = 72 0-15: Source Port 16-31: Destination Port 32-63: Sequence Number 64-95: Acknowledgment Number 96-99: Data Offset 100-105: Reserved 106: URG 107: ACK 108: PSH 109: RST 110: SYN 111: FIN 112-127: Window 128-143: Checksum 144-159: Urgent Pointer 160-191: (Options and Padding) 192-223: data [colheight = 3]&#125;]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>diagram</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oslo 源码分析之 context]]></title>
    <url>%2F2018%2F06%2F03%2Foslo-context%2F</url>
    <content type="text"><![CDATA[在介绍源码之前，我们先谈谈什么是 context. 一开始不太理解什么是 context，其实它是一个统称，在不同的地方有不同的含义，所以不是很直白。context 翻译成中文是“上下文”的意思，说白了和文章的上下文是一个意思，通俗一点讲就是环境。例如用户信息，token 之类的。如果还是不明白，看看下面的例子。 openstack 的 context 主要是用来保存 http request 相关信息。 context 模块主要定义了一个 RequestContext 类，里面保存了跟 request 请求相关的信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class RequestContext(object): """Helper class to represent useful information about a request context. Stores information about the security context under which the user accesses the system, as well as additional request information. """ user_idt_format = u'&#123;user&#125; &#123;tenant&#125; &#123;domain&#125; &#123;user_domain&#125; &#123;p_domain&#125;' # Can be overridden in subclasses to specify extra keys that should be # read when constructing a context using from_dict. FROM_DICT_EXTRA_KEYS = [] @_renamed_kwarg('user', 'user_id') @_renamed_kwarg('tenant', 'project_id') @_renamed_kwarg('domain', 'domain_id') @_renamed_kwarg('user_domain', 'user_domain_id') @_renamed_kwarg('project_domain', 'project_domain_id') def __init__(self, auth_token=None, user_id=None, project_id=None, domain_id=None, user_domain_id=None, project_domain_id=None, is_admin=False, read_only=False, show_deleted=False, request_id=None, resource_uuid=None, overwrite=True, roles=None, user_name=None, project_name=None, domain_name=None, user_domain_name=None, project_domain_name=None, is_admin_project=True, service_token=None, service_user_id=None, service_user_name=None, service_user_domain_id=None, service_user_domain_name=None, service_project_id=None, service_project_name=None, service_project_domain_id=None, service_project_domain_name=None, service_roles=None, global_request_id=None, system_scope=None): """Initialize the RequestContext :param overwrite: Set to False to ensure that the greenthread local copy of the index is not overwritten. :param is_admin_project: Whether the specified project is specified in the token as the admin project. Defaults to True for backwards compatibility. :type is_admin_project: bool :param system_scope: The system scope of a token. The value ``all`` represents the entire deployment system. A service ID represents a specific service within the deployment system. :type system_scope: string """ # setting to private variables to avoid triggering subclass properties self._user_id = user_id self._project_id = project_id self._domain_id = domain_id self._user_domain_id = user_domain_id self._project_domain_id = project_domain_id self.auth_token = auth_token self.user_name = user_name self.project_name = project_name self.domain_name = domain_name self.system_scope = system_scope self.user_domain_name = user_domain_name self.project_domain_name = project_domain_name self.is_admin = is_admin self.is_admin_project = is_admin_project self.read_only = read_only self.show_deleted = show_deleted self.resource_uuid = resource_uuid self.roles = roles or [] self.service_token = service_token self.service_user_id = service_user_id self.service_user_name = service_user_name self.service_user_domain_id = service_user_domain_id self.service_user_domain_name = service_user_domain_name self.service_project_id = service_project_id self.service_project_name = service_project_name self.service_project_domain_id = service_project_domain_id self.service_project_domain_name = service_project_domain_name self.service_roles = service_roles or [] if not request_id: request_id = generate_request_id() self.request_id = request_id self.global_request_id = global_request_id if overwrite or not get_current(): self.update_store() 先看官方文档给的一个例子： 123456789101112131415from oslo_config import cfgfrom oslo_context import contextfrom oslo_log import log as loggingCONF = cfg.CONFDOMAIN = "demo"logging.register_options(CONF)logging.setup(CONF, DOMAIN)LOG = logging.getLogger(__name__)LOG.info("Message without context")context.RequestContext()LOG.info("Message with context") 上面的代码打印结果如下： 122016-01-20 21:56:29.283 8428 INFO __main__ [-] Message without context2016-01-20 21:56:29.284 8428 INFO __main__ [req-929d23e9-f50e-46ae-a8a7-02bc8c3fd2c8 - - - - -] Message with context 看到上面的打印，有些人可能会有疑问，代码中只创建了 context.RequestContext 对象，并未赋值给 LOG, LOG 是怎么获取 request_id 的，实际上，RequestContext 对象创建之后会保存在 threading.local() 中，所以当前线程的其它代码都可以读取到 RequestContext 的值。]]></content>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go string 连接性能测试]]></title>
    <url>%2F2018%2F04%2F28%2Fgo-string%2F</url>
    <content type="text"><![CDATA[我们常使用字符串拼接，当比较小时，使用哪种方式都差不多，但是当拼接数比较大时，不同的方法效率会相差很大。 go 提供了如下几种方式连接字符串: strings.Join fmt.Sprintf += strings.Builder (go 1.10 提供) 我们先简单测试下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt" "time" "strings")func main() &#123; var sz int = 100000 // += 方式 t0 := time.Now() var s string for i := 0; i &lt; sz; i ++ &#123; s += "a" &#125; d0 := time.Since(t0) fmt.Printf("time of [+=]: %v\n", d0) // strings.Join 方式 t1 := time.Now() var s1 string for i := 0; i &lt; sz; i++ &#123; s1 = strings.Join([]string&#123;s1, "a"&#125;, "") &#125; d1 := time.Since(t1) fmt.Printf("time of Join: %v\n", d1) // Sprintf t2 := time.Now() var s2 string for i := 0; i &lt; sz; i++ &#123; s2 = fmt.Sprintf("%s%s", s2, "a") &#125; d2 := time.Since(t2) fmt.Printf("time of Sprintf: %v\n", d2) // string.Builder t3 := time.Now() var b strings.Builder for i :=0; i &lt; sz; i++ &#123; b.WriteString("a") &#125; d3 := time.Since(t3) fmt.Printf("time of Builder: %v\n", d3)&#125; 结果: 1234time of [+=]: 1.1500289stime of Join: 1.1507809stime of Sprintf: 1.5668042stime of Builder: 1.992ms 可以看出 +=, strings.Join, fmt.Sprintf 效率相差不大，但是 strings.Builder 的效率却高了 1000倍。为什么 strings.Builder 如此变态，我们看下实现： strings.Join 底层是用 += 和 copy 实现的，所以效率和 += 差不多 strings.Builder 使用 []type 数组实现; strings.Builder 实现Builder 可以用最小的内存拷贝来构建字符串。先看下 Builder 的简单实现: 1234567891011121314151617181920212223type Builder struct &#123; addr *Builder // of receiver, to detect copies by value buf []byte&#125;func (b *Builder) copyCheck() &#123; if b.addr == nil &#123; // This hack works around a failing of Go's escape analysis // that was causing b to escape and be heap allocated. // See issue 23382. // TODO: once issue 7921 is fixed, this should be reverted to // just "b.addr = b". b.addr = (*Builder)(noescape(unsafe.Pointer(b))) &#125; else if b.addr != b &#123; panic("strings: illegal use of non-zero Builder copied by value") &#125;&#125;func (b *Builder) WriteString(s string) (int, error) &#123; b.copyCheck() b.buf = append(b.buf, s...) return len(s), nil&#125; 可以看出 Builder 底层是用 []byte 实现的，每次添加字符串时，都是直接向数组最后插入值完成的，减少了不必要的内存拷贝，所以效率比较搞。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nose 使用]]></title>
    <url>%2F2018%2F04%2F28%2Fnose%2F</url>
    <content type="text"><![CDATA[使用nose进行单元测试nose 是一个很 nice 的 python 测试框架，使用起来非常方便。有些 openstack 项目也使用 nova 进行单元测试。 nose安装1pip install nose Example例如我们在multiply.py文件中有如下一段代码: 12def multiply(x, y): return x * y 为了测试上面的代码，我们添加test_multiply.py，编写如下内容： 123456789from multiply import multiplydef test_number_3_4(): assert multiply(3, 4) == 12def test_strings_a_3(): assert multiply('a', 3) == 'aaa' 运行nosetests,打印结果如下： 123456yl@lee:~/code/py/project$ nosetests..----------------------------------------------------------------------Ran 2 tests in 0.001sOK 如果要查看详细信息我们可以添加-v参数： 12345678yl@lee:~/code/py/project$ nosetests -vmultiply_test.test_number_3_4 ... okmultiply_test.test_strings_a_3 ... ok----------------------------------------------------------------------Ran 2 tests in 0.001sOK nose会自动匹配test用例，匹配规则是：满足(?:^|[b_.-])[Tt]est的类，函数，目录，方法。 nose fixtures在测试一组用例的时候，有些初始化或结束代码是通用的，我们可以把这部分代码提取出来，放到setup和teardown中。 在module生效，使用setup_module/teardown_module 在class生效，使用setup_class/teardown_class，并添加@classmethod装饰器 function使用setup_function/teardown_function,并添加@with_setup装饰器 备注 setup_module(): 在文件中最早执行 teardown_module(): 在文件中最后执行 setup()在类所有方之前执行 teardown()在类所有方法之后执行 setup_class()在类每个方法开始时执行 teardown_class()在类每个方法最后执行 具体例子如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from nose import with_setup # optionalfrom unnecessary_math import multiplydef setup_module(module): print ("") # this is to get a newline after the dots print ("setup_module before anything in this file")def teardown_module(module): print ("teardown_module after everything in this file")def my_setup_function(): print ("my_setup_function")def my_teardown_function(): print ("my_teardown_function")@with_setup(my_setup_function, my_teardown_function)def test_numbers_3_4(): print 'test_numbers_3_4 &lt;============================ actual test code' assert multiply(3,4) == 12@with_setup(my_setup_function, my_teardown_function)def test_strings_a_3(): print 'test_strings_a_3 &lt;============================ actual test code' assert multiply('a',3) == 'aaa'class TestUM: def setup(self): print ("TestUM:setup() before each test method") def teardown(self): print ("TestUM:teardown() after each test method") @classmethod def setup_class(cls): print ("setup_class() before any methods in this class") @classmethod def teardown_class(cls): print ("teardown_class() after any methods in this class") def test_numbers_5_6(self): print 'test_numbers_5_6() &lt;============================ actual test code' assert multiply(5,6) == 30 def test_strings_b_2(self): print 'test_strings_b_2() &lt;============================ actual test code' assert multiply('b',2) == 'bb' 默认情况下nose不会打印程序的输出，加上-s参数可以打印输出 123456789101112131415161718192021222324252627yl@lee:~/code/py/project$ nosetests -v -ssetup_module before anything in this filesetup_class() before any methods in this classmultiply_test.TestUM.test_numbers_5_6 ... TestUM:setup() before each test methodtest_numbers_5_6() &lt;============================ actual test codeTestUM:teardown() after each test methodokmultiply_test.TestUM.test_strings_b_2 ... TestUM:setup() before each test methodtest_strings_b_2() &lt;============================ actual test codeTestUM:teardown() after each test methodokteardown_class() after any methods in this classmultiply_test.test_numbers_3_4 ... my_setup_functiontest_numbers_3_4 &lt;============================ actual test codemy_teardown_functionokmultiply_test.test_strings_a_3 ... my_setup_functiontest_strings_a_3 &lt;============================ actual test codemy_teardown_functionokteardown_module after everything in this file----------------------------------------------------------------------Ran 4 tests in 0.002sOK 使用nose assert语句1234from nose.tools import assert_equalsdef test_numbers_3_4(): assert_equals(multiply(3,4), 12) 常用assert语句如下： assert_almost_equal(first, second, places=7, msg=None) assert_almost_equals assert_not_almost_equal assert_not_almost_equals assert_equal(first, second, place=7, msg=None) assert_equals assert_false assert_true assert_not_equal assert_not_equals eq_ ok_ 异常处理有时候我们会在程序的某些地方抛异常，对于这种情况，需要使用@raises装饰器处理。 1234567def play(): sys.exit(1)from nose.tools import raises@raises(SystemExit)def test_play_except(): play() 常用参数 nosetests -v： debug模式，看到具体执行情况，推荐使用； nose会捕获标准输出，程序中的print不会打印到出来，使用nosetests -s可以打开output输出； 默认nosetests会执行所有的test case，如果想单独执行一个case，执行nosetests –tests后跟要测试的文件； nosetests –pdb-failures:失败时，立马调试。这个选项很赞，可以看到失败时的及时环境； nosetests –collect-only -v: 不运行程序，只是搜集并输出各个case的名称； nosetests -x:一旦case失败，立即停止，不执行后续case; nosetestx -failed:只执行上一轮失败的case; 命名规范 module使用 ‘test_’开头 fucntion使用 ‘tets_’开头 class使用 ‘Test’开头 method使用’test_’开头 测试代码的package里有’init.py’ 获取nose返回值 shell在shell下执行时，如果全部用例都通过，则返回0，有failed或error则返回1。 python在python代码中调用nose.run()函数，如果全部用例都通过，返回True，有failed或error返回False。 默认情况下，nose会屏蔽所有输出，如果要打开调试信息可以通过如下方式： 1result = nose.run(defaultTest="", argv=['', '--nocapture'])]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 迭代器和生成器]]></title>
    <url>%2F2018%2F04%2F23%2Fiterator%2F</url>
    <content type="text"><![CDATA[在 python 中我们常用 for in 来遍历 list, set, dict, str 等。for in 的本质就干了两件事： 调用 __iter__() 获取迭代器; 调用 next() 直到 StopIteration 异常; (python3 中是 __next__()) 迭代器我们先了解几个概念： Iterable: 可迭代对象 Iterator: 迭代器 我们先看看 Iterable 的实现1234567891011121314151617181920212223242526272829303132333435from collections import Iterablehelp(Iterable)class Iterable(__builtin__.object) | Methods defined here: | | __iter__(self) | | ---------------------------------------------------------------------- | Class methods defined here: | | __subclasshook__(cls, C) from abc.ABCMeta | | ---------------------------------------------------------------------- | Data descriptors defined here: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) | | ---------------------------------------------------------------------- | Data and other attributes defined here: | | __abstractmethods__ = frozenset(['__iter__']) | | __metaclass__ = &lt;class 'abc.ABCMeta'&gt; | Metaclass for defining Abstract Base Classes (ABCs). | | Use this metaclass to create an ABC. An ABC can be subclassed | directly, and then acts as a mix-in class. You can also register | unrelated concrete classes (even built-in classes) and unrelated | ABCs as 'virtual subclasses' -- these and their descendants will 再看看 Iterator 的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from collections import Iteratorhelp(Iterator)class Iterator(Iterable) | Method resolution order: | Iterator | Iterable | __builtin__.object | | Methods defined here: | | __iter__(self) | | next(self) | Return the next item from the iterator. When exhausted, raise StopIteration | | ---------------------------------------------------------------------- | Class methods defined here: | | __subclasshook__(cls, C) from abc.ABCMeta | | ---------------------------------------------------------------------- | Data and other attributes defined here: | | __abstractmethods__ = frozenset(['next']) | | ---------------------------------------------------------------------- | Data descriptors inherited from Iterable: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) | | ---------------------------------------------------------------------- | Data and other attributes inherited from Iterable: | | __metaclass__ = &lt;class 'abc.ABCMeta'&gt; | Metaclass for defining Abstract Base Classes (ABCs). | | Use this metaclass to create an ABC. An ABC can be subclassed | directly, and then acts as a mix-in class. You can also register | unrelated concrete classes (even built-in classes) and unrelated | ABCs as 'virtual subclasses' -- these and their descendants will | be considered subclasses of the registering ABC by the built-in | issubclass() function, but the registering ABC won't show up in | their MRO (Method Resolution Order) nor will method | implementations defined by the registering ABC be callable (not | even via super()). 从继承关系来看，所有的 Iterator(迭代器)都是 Iterable(可迭代对象)，从实现角度看 Iterator 新增了 next() 方法。 判断是 Iterator 还是 Iterable 凡是可以 for 循环的，都是 Iterable; 凡是可以 next() 的，都是 Iterator; list, tuple, dict, str, set 都不是 Iterator，但是可以通过 __iter__() 返回一个 Iterator 对象 12345678910111213141516from collections import Iterator, Iterableisinstance([1,], Iterator) // Falseisinstance((1,), Iterator) // Falseisinstance(&#123;&#125;, Iterator) // Falseisinstance("abc", Iterator) // Falseisinstance(set([]), Iterator) // Falseisinstance([1,], Iterable) // Trueisinstance((1,), Iterable) // Trueisinstance(&#123;&#125;, Iterable) // Trueisinstance("abc", Iterable) // Trueisinstance(set([]), Iterable) // Truedir([]) // 没有 next() 方法dir([].__iter__()) // 有 next() 方法 生成器讲完了迭代器，我们再说说生成器，这里引用廖雪峰博客里的介绍: 通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器（Generator）。 生成器的创建很简单，可以通过推导列表创建： 1g = (x * x for x in range(10)) // 使用 [] 返回的是 list, () 返回的是 generator 还有一种方式是通过 yield 关键字生成。 先看看生成器的实现: 12345678910111213141516171819202122232425262728293031323334&lt;genexpr&gt; = class generator(object) | Methods defined here: | | __getattribute__(...) | x.__getattribute__('name') &lt;==&gt; x.name | | __iter__(...) | x.__iter__() &lt;==&gt; iter(x) | | __repr__(...) | x.__repr__() &lt;==&gt; repr(x) | | close(...) | close() -&gt; raise GeneratorExit inside generator. | | next(...) | x.next() -&gt; the next value, or raise StopIteration | | send(...) | send(arg) -&gt; send 'arg' into generator, | return next yielded value or raise StopIteration. | | throw(...) | throw(typ[,val[,tb]]) -&gt; raise exception in generator, | return next yielded value or raise StopIteration. | | ---------------------------------------------------------------------- | Data descriptors defined here: | | gi_code | | gi_frame | | gi_running 可以发现生成器较迭代器多了 send, throw 等方法。 send这里重点介绍下 send 方法，我们知道在使用迭代器时，遇到 yield 关键字会退出来，下一迭代时会继续执行。先看个例子： 1234567def MyGenerator(): value = yield 1 value = yield valuegen = MyGenerator()print gen.next() // print 1print gen.next() // print None 我们看看具体执行过程： 调用 next() 方法，走到 yield 1 退出，注意这个时候还没有走到 value 的 赋值操作(即: value = yield 1 只执行了右侧部分) 调用 next() 方法，继续上次的代码执行(即：value = yield 1 只执行了右侧的赋值部分) 由于 yield 并没有返回值，所以 value = None 返回 None, 并打印 修改下上面的例子： 1234567def MyGenerator(): value = yield 1 value = yield valuegen = MyGenerator()print gen.next() // print 1print gen.send(2) // print 2 send 方法是指定的是上一次被挂起的yield语句的返回值，这么说有点抽象，我们看执行过程： 调用 next() 方法，走到 yield 1 退出，注意这个时候还没有走到 value 的 赋值操作(即: value = yield 1 只执行了右侧部分) 调用 send(2) 方法，继续上次的代码执行(即：value = yield 1 只执行了右侧的赋值部分) value 使用 send 传的值，即： value = 2 返回 2, 并打印 协程协程就是利用 yield 和生成器的 send() 方法实现的。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 常用技巧]]></title>
    <url>%2F2018%2F04%2F22%2Fshell%2F</url>
    <content type="text"><![CDATA[输出颜色控制123RED=&apos;\033[0;31m&apos;NC=&apos;\033[0m&apos;echo &quot;$&#123;RED&#125;hello world!$&#123;NC&#125;&quot;]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go_http]]></title>
    <url>%2F2018%2F04%2F20%2Fgo-http%2F</url>
    <content type="text"><![CDATA[先看一个简单的 tcp 连接: 123456789101112131415// serverln, err := net.Listen("tcp", ":8000")if err != nil &#123;&#125;for &#123; conn, err := ln.Accept() if err != nil &#123; continue &#125; go handleConnection(conn)&#125;// clientconn, err := net.Dial("tcp", ":8000")if err != nil &#123;&#125;status, err := bufio.NewReader(conn).ReadString('\n') http server起一个 http server 有两种方式，分别是 http.Server.ListenAndServe() 和 http.ListenAndServe(),两者在本质上是相同的。 监听 http123456// 创建 tcp 连接s := &amp;http.Server&#123;&#125;s.ListenAndServe()// 这里会创建一个 http.Server，然后调用 ListenAndServehttp.ListenAndServe(":80808", nil)]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go 结构体]]></title>
    <url>%2F2018%2F04%2F18%2Fgo-struct%2F</url>
    <content type="text"><![CDATA[go 语言中结构体有点类似 OOP 语言中的类，但是又有着很大区别。go 使用大小写来控制属性的访问权限，如果首字母大写在其它包中可以被访问，否则只能在本包中访问 结构体声明123456789type Employee struct &#123; ID int Name string Address string DoB time.Time Position string Salary int ManagerID int&#125; 对象声明及初始化123456789// 这个时候 dibert 已经初始化并可以使用了，所有值使用零值初始化var dilbert Employee// e1, e3 返回的是指针类型e1 := new(Employee)e2 := Employee&#123;ID: 1, Name: "Lee"&#125;e3 := &amp;Employee&#123;1, "lee"&#125;初始化的时候如果使用 `k: v` 可以打乱顺序，如果是 `v1, v2` 则必须和结构体声明顺序一致。 1234// 指针类型// 直接声明指针是没有初始化的// 直接访问变量会报 panic: runtime error: invalid memory address or nil pointer dereferencevar e4 *Employee 属性访问1fmt.Println(dilbert.Name) 方法定义go 的 struct 有点类似其它语言的 class, 但是又有些差异。 123456func (e *Employee) Print() &#123; fmt.Println(e.Name)&#125;// 使用dibert.Print() 匿名字段声明一个结构体可以只写类型，不写 value，最常见的就是锁的使用，eg: 12345678type Node struct &#123; sync.RWMutex Name string&#125;// 使用匿名字段var node Nodenode.Lock // 调用的是 sync.RWMutex.Lock() 匿名结构体1a := &amp;struct&#123;&#125;&#123;&#125;]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 常用命令]]></title>
    <url>%2F2017%2F05%2F08%2Fdocker-cmd%2F</url>
    <content type="text"><![CDATA[记录 docker 常用命令。 image 查看创建信息 1$ sudo docker histroy &lt;image_id&gt; network 查看容器 IP 1$ docker inspect --format='&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' $CONTAINER_ID container创建容器 启动参数: -i: interactive 交互模式; -t: tty; -d: 后台运行; 12# tty 登录docker run -i -t &lt;images_id&gt; /bin/bash 进入后台运行的容器 1234567891011# 使用 namedocker attach &lt;name&gt;# 使用 iddocker attach &lt;id&gt;# 使用 namedocker exec -it &lt;name&gt; /bin/bash# 使用 iddocker exec -it &lt;id&gt; /bin/bash attach 和 exec 的区别在于 exec 执行 exit 时不会 stop 容器，而 attach 会 stop 容器。 重命名 1$ docker rename &lt;current_name&gt; &lt;new_name&gt; 删除容器 12# 删除所有docker rm -f $(docker ps -a -q) 文件拷贝12345# host -&gt; containerdocker cp &lt;host_path&gt; &lt;containerID&gt;:&lt;container_path&gt;# container -&gt; hostdocker cp &lt;containerID&gt;:&lt;container_path&gt; &lt;host_path&gt; 查看容器信息1$ sudo docker inspect tox]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ip 命令使用]]></title>
    <url>%2F2017%2F04%2F30%2Fip%2F</url>
    <content type="text"><![CDATA[ip命令用来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具。 tun/tap 设备12345# createsudo ip tuntap add dev tap-node-0i2 mode tap# deletesudo ip tuntap del dev tap-node-0i2 mode tap 创建 veth pair1ip link add veth_0 type veth peer name veth_0_peer Configure 802.1Q VLAN Tagging1234567891011$ # add$ sudo ip link add link enp2s0 name enp2s0.100 type vlan id 100$ # delete$ sudo ip link del dev enp2s0.100$ # show$ ip -d link show enp2s0.10019: enp2s0.100@enp2s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 50:7b:9d:1b:34:df brd ff:ff:ff:ff:ff:ff promiscuity 0 vlan protocol 802.1Q id 100 &lt;REORDER_HDR&gt; addrgenmode eui64 网口操作12345678# 查看网口状态ip addr show# ifupip link set ens4 up# 设置 ip 地址ip addr add 10.5.1.23/24 dev enp132s0f0 路由查看路由表123$ ip route show$ route -n$ netstat -rn 根据 IP 查路由12$ ip route get 10.0.2.1410.0.2.14 dev eth0 src 10.0.2.15]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 常用命令]]></title>
    <url>%2F2017%2F04%2F08%2Fgit%2F</url>
    <content type="text"><![CDATA[git 实用汇总，很多小技巧，开发中经常遇到，速查手册。 stash有时候我们一个功能开发了一半，不想 commit 也不想丢掉，这个时候可以用 stash 解决。 123456789101112# 把修改暂存起来git add --allgit stash# 查看刚刚的暂存信息git stash list# 需要继续开发，把暂存的东西 pop 出来git stash pop# 现在再看暂存列表，已经没有之前的记录了git stash list 只提交部分文件12345678910# 提交指定文件git add a.go b.go c.gogit commit -m "add some file"# 查看状态，确定还有未提交文件git status# 暂存git add -allgit stash 取消 add1git reset HEAD a.go 已经修改，未 add, 变成未修改状态1234git checkout -- a.go# 如果想把所有文件都变成未修改状态git checkout -- . 取消 commit已经 commit 了，但是不想要了，想回到上一个 commit 重写 12345#回到上一个 commit，把这个 commit 的修改变为 unstaged changesgit reset HEAD^# 把 unstaged changes 变回未修改状态git checkout -- . revert有时候我们代码已经 push 了，但是不想要了： 12345678# 回到上次代码git reset HEAD^git checkout -- .git push -f# 或者温柔点的做法git revert HEADgit push 把其它分支代码更新到当前分支1git pull origin master:master submoduleGit 子模块功能允许你将一个Git仓库当作另外一个Git仓库的子目录。这允许你克隆另外一个仓库到你的项目中并且保持你的提交相对独立。 12345# 添加子模块git submodule add 仓库地址 路径# 下载子模块git submodule update --init --recursive orphan 使用当我们需要创建一个全新的分支时，而又不希望继承任何其它分支，可以使用 –orphan 参数, eg: 1git checkout --orphan dev 此时新创建的分支会有原始分支的代码，直接删除即可，然后添加我们新的代码。 查看配置信息1git config --global --list 设置信息12345git config --global user.name "yourname"git config --global user.email "yourname@test.com"# 代理git config --global http.proxy http://proxy.com:80 获取最后一次提交信息123456# 最后一次所有信息git log -1# 最后一次commit idgit rev-parse HEAD# 最后一个commit信息git log -1 --pretty=%B cherry pick使用有时候他们需要在多个分支上提交相同的代码，如果每一个都改一遍就太麻烦了。这时候可以使用cherry pick，具体操作如下： 例如你现在 dev分支合入代码，并且已经提交。 git log 查看你提交的commit 号 12345commit 3e54a734e42bb8f9e2c32c193de741432f544d28Author: yourname &lt;yourname@test.com&gt;Date: Fri Apr 29 14:13:16 2016 +0800 614005245543 upgrade librados2* librbd1* git checkout 其它分支 git cherry-pick 查询到的commit号（例如上面的3e54a734e42bb8f9e2c32c193de741432f544d28） 这个时候你用git status 命令查看，切换的分支代码是已经add和commit的，由于不同的分支我们使用的EC单号不同，这个时候我们需要修改commit信息 使用git commit –amend 这个时候git会自动调用vi打开你的commit信息，你编辑成新的就可以了。 使用git push origin 远程分支名 提交代码 创建远程分支12# eg: 本地分支名为 dev01, 创建远程分支 dev01git push origin dev01:dev01]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack 社区代码提交]]></title>
    <url>%2F2016%2F09%2F07%2Fcontribute%2F</url>
    <content type="text"><![CDATA[网站介绍 launchpad lanuchpad 主要是社区用来记录 bug 和 bp 的地方; openstack openstack 的官方网站; gerrit 下载代码，评审; 前期准备 注册 launchpad 帐号; 注册 openstack 帐号; 登录 https://review.openstack.org; 进入 https://review.openstack.org/#/settings/ 在里面填写如下信息： 在Profile中的Username 在Agreements中签署协议（个人是ICLA) 在Contact Infomation中填写所有内容，注意如果之前不是Foundation Member就会出现无法提交问题 在HTTP Password中Generate Password，生成一串代码。后续提交代码时需要用到这串密码 提交代码在提交代码之前我们需要做一些简单的配置。 git review安装1pip install git-review git 配置12345678# 这里的名字必须是gerrit的名字git config gitreview.username &lt;your name&gt;# ssh用不了，使用https方式提交git config gitreview.scheme httpsgit config gitreview.port 443git review -s -v 提交代码1234git add --allgit commit -m "commit msg"git review 如果已经 commit 完了，发现还有代码需要修改，我们需要追加 commit. 12# 可以编辑 commit 信息git commit --amend 邮件列表订阅直接访问 Mailing list 退订如果感觉邮件列表太多，可以退订邮件列表： http://lists.openstack.org/cgi-bin/mailman/options/openstack-dev]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovs 常用命令]]></title>
    <url>%2F2016%2F05%2F01%2Fovs%2F</url>
    <content type="text"><![CDATA[连接网桥例如现有两个 ovs 桥 br-1 和 br-2, 这两个桥上都挂有虚机， 如果不做处理，两个桥之间的虚机是不通的，如下图所示，要在 vm2 中访问 vm4, 需要把两个桥打通，或者有一个机器同时接到两个桥。 12345678910111213141516171819+----------------------+| || +-----+ +-----+ || | vm1 | | vm2 | || +-----+ +-----+ || | | || +----------+ || | br-1 | || +----------+ || | || | || +----------+ || | br-2 | || +----------+ || | | || +-----+ +-----+ || | vm4 | | vm3 | || +-----+ +-----+ |+----------------------+ 创建 peer 口： 123456789101112131415161718192021222324252627# ovs-vsctl add-br br-1# ovs-vsctl add-br br-2# ovs-vsctl add-port br-1 patch-br2 -- set Interface patch-br2 type=internal# ovs-vsctl add-port br-2 patch-br1 -- set Interface patch-br1 type=internal# ovs-vsctl set interface patch-br2 options:peer=patch-br1# ovs-vsctl set interface patch-br1 options:peer=patch-br2# ovs-vsctl showc0618d27-6364-4e3f-9e38-f5c520575954 Bridge "br-1" Port "br-1" Interface "br-1" type: internal Port "patch-br2" Interface "patch-br2" type: internal options: &#123;peer="patch-br1"&#125; Bridge "br-2" Port "br-2" Interface "br-2" type: internal Port "patch-br1" Interface "patch-br1" type: internal options: &#123;peer="patch-br2"&#125; VLAN 设置123456# ovs-vsctl set port &#123;port&#125; vlan_mode=access# ovs-vsctl set port &#123;port&#125; tag=&#123;segmentation_id&#125;# ovs-vsctl clear port &#123;port&#125; tag# ovs-vsctl clear port &#123;port&#125; trunks# ovs-vsctl clear port &#123;port&#125; vlan_mode 查看 interface 信息1234567891011121314151617181920212223242526272829303132333435# ovs-vsctl list interface tapaf2a9c21-d7_uuid : 7b32826b-dcf6-4e69-8b2c-0c8f7da946a0admin_state : downbfd : &#123;&#125;bfd_status : &#123;&#125;cfm_fault : []cfm_fault_status : []cfm_flap_count : []cfm_health : []cfm_mpid : []cfm_remote_mpids : []cfm_remote_opstate : []duplex : []error : []external_ids : &#123;attached-mac="fa:16:3e:d6:f8:96", iface-id="af2a9c21-d7c3-485b-a869-af701ab53ba2", iface-status=active&#125;ifindex : 0ingress_policing_burst: 0ingress_policing_rate: 0lacp_current : []link_resets : 0link_speed : []link_state : downlldp : &#123;&#125;mac : []mac_in_use : []mtu : []mtu_request : []name : "tapaf2a9c21-d7"ofport : 6ofport_request : []options : &#123;&#125;other_config : &#123;&#125;statistics : &#123;collisions=0, rx_bytes=488, rx_crc_err=0, rx_dropped=0, rx_errors=0, rx_frame_err=0, rx_over_err=0, rx_packets=5, tx_bytes=438, tx_dropped=0, tx_errors=0, tx_packets=5&#125;status : &#123;driver_name=openvswitch&#125;type : internal 查看流表1# ovs-ofctl dump-flows brbm]]></content>
      <categories>
        <category>kvm</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virsh 常用命令]]></title>
    <url>%2F2016%2F04%2F30%2Fvirsh%2F</url>
    <content type="text"><![CDATA[virsh 是 libvirt 的 cli 工具，通过调用 libvirt 接口来控制虚拟机。 常用命令1234567891011121314151617# 查看虚机列表$ virsh listId Name State---------------------------------------------------- 3 dev_test running# 查看网络$ virsh net-list# dumpxml$ virsh dumpxml &lt;id&gt;# 查看 vnc 端口号$ virsh vncdisplay &lt;id&gt;# 增加网卡virsh attach-interface --domain vm1 --type bridge --source br1]]></content>
      <categories>
        <category>kvm</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qemu 常用命令]]></title>
    <url>%2F2016%2F04%2F30%2Fqemu%2F</url>
    <content type="text"><![CDATA[镜像基本操作12345# 创建镜像$ qemu-img create -f &lt;format&gt; &lt;filename&gt; &lt;size&gt;# 查看镜像信息$ qemu-img info &lt;filename&gt; 格式转换1$ qemu-img convert -c -f &lt;fmt&gt; -O &lt;out_fmt&gt; -o &lt;options&gt; &lt;fname&gt; &lt;out_fname&gt; 扩容1$ qemu-img resize test.img +2G qemu-img 快照1234567891011121314# 创建快照$ qemu-img snapshot -c first_snapshot /var/lib/test.img# 查询快照$ qemu-img snapshot -l /var/lib/test.imgSnapshot list:ID TAG VM SIZE DATE VM CLOCK1 first_snapshot 0 2017-07-11 09:30:40 00:00:00.000# 使用快照$ qemu-img snapshot -a 1 /var/lib/test.img# 删除快照$ qemu-img snapshot -d 1 /var/lib/test.img qemu 镜像修改有时候当我们的qemu 镜像系统挂了或者是没有密码时，我们可以挂载qemu镜像，然后对镜像进行修改和文件备份。操作步骤如下： 挂载qcow2 123modprobe nbd max_part=8qemu-nbd -c /dev/nbd0 vdisk01.imgmount /dev/nbd0p1 /mnt/ 挂载lvm分区 qcow2镜像 123vgscanvgchange -aymount /dev/VolGroupName/LogVolName /mnt/ 卸载qcow2 123umount /mnt/vgchange -an VolGroupNamekillall qemu-nbd]]></content>
      <categories>
        <category>kvm</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
</search>
